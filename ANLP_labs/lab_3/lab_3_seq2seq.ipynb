{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDxS8RLD9Mf1"
   },
   "source": [
    "# Lab 3: Sequence-to-Sequence Modeling with Recurrent Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybdRfjvbDI4A"
   },
   "source": [
    "The objective of this lab is to _implement, train, and evaluate a recurrent neural network (RNN)-based sequence-to-sequence (seq2seq) model_. Well, that's a mouthful, so let's unpack the two key terms.\n",
    "\n",
    "A **Recurrent Neural Network** (RNN) is a type of neural network designed to handle sequences, like text or speech. It processes one item of the sequence at a time and carries a hidden state—a kind of short-term memory—that summarises the history of the sequence observed so far. The same weights are reused at each time step, letting it learn patterns over time.\n",
    "\n",
    "\n",
    "**Sequence-to-sequence learning** is a framework used for tasks in which both the input and the output are variable-length sequences that are not necessarily aligned, such as machine translation or summarization. Nowadays, in general-purpose AI models most tasks are framed as seq2seq, where both the input (e.g., task instructions and a question) and the output (e.g., a reasoning trace and an answer) are sequences.\n",
    "\n",
    "In this lab, we apply the seq2seq RNN to a toy task, the SCAN dataset, mapping a sequence of textual instructions into a sequence of actions. With all due differences, this is the stripped down version of commanding a robot!\n",
    "\n",
    "**Important**: Not all student pairs will be able to complete all sections and exercises of this lab: and that is fine! Most students should be able to reach the end of section 7 (\"Evaluating the model\"). If you do not manage to complete Section 8 (\"Out-of-distribution generalisation\") in time during the lab session, you are invited to revisit it at your own convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1vnik59EUTj"
   },
   "source": [
    "## What you will learn in this lab\n",
    "\n",
    "### Tools and practical issues:\n",
    "\n",
    "In this lab, you will learn:\n",
    "- how to preprocess and batch examples when they have different lengths\n",
    "- how to implement a sequence-to-sequence model\n",
    "- how to train this model through stochastic gradient descent\n",
    "- how to evaluate your model's predictions on a series of metrics, which measure exact match and overlap wrt a reference\n",
    "- to read the documentation of a library and use it\n",
    "\n",
    "### Concepts: sequence-to-sequence models and generalisation\n",
    "\n",
    "After working through the lab, you should be able to:\n",
    "- explain the different challenges in sequence to sequence modelling\n",
    "- understand the difference between i.i.d. and out-of-distribution generalisation\n",
    "   \n",
    "You should also understand more clearly:\n",
    "- how neural models are optimised\n",
    "- how choices in the neural model architecture affect its accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNY9VAhAVU3U"
   },
   "source": [
    "# 1. Install and import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_sXQ-DY1T32"
   },
   "source": [
    "Let's first install and import the necessary dependencies. Most notably:\n",
    "\n",
    "\n",
    "\n",
    "*   `torch` (Pytorch), a library for implementing deep learning models, training them, and evaluating them.\n",
    "*   `wandb` (Weights & Biases), a library to track metrics from your experiments.\n",
    "\n",
    "_Optional: If you are not familiar with the other libraries, you can find the documentation for most of them on https://docs.python.org/3/library/_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hT4G0wBlDJ54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feb58114570>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q wandb\n",
    "!pip install -q evaluate\n",
    "!pip install -U -q datasets\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import evaluate\n",
    "\n",
    "# Tracking\n",
    "import wandb\n",
    "\n",
    "# Set random seeds to make our experiments (almost) deterministic\n",
    "# This makes it easier to reproduce results\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSAlkZ4lVZN7"
   },
   "source": [
    "# 2. Compositionality and the SCAN dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dwh0JdxEn5X"
   },
   "source": [
    "**Compositional generalisation** is the ability to understand and produce a potentially infinite number of novel combinations from known components. This is the case of natural language, where infinite sentences can be construed from a finite number of words.\n",
    "\n",
    "For example, assume a person knows the meaning and usage of words such as \"*twice*\" and \"*again*\" and then learns a new (imaginary) verb such as \"*to dax*\". Through compositional generalisation, they can immediately understand or produce instructions such as \"*dax twice*\" or \"*dax again*\" even if they haven't encountered these specific combinations before.\n",
    "\n",
    "With the growing capabilities of machine learning models, researchers have become increasingly interested in testing whether such models can replicate this key aspect of human language.\n",
    "To support systematic investigation of this question, the **SCAN dataset** was introduced by [Lake and Baroni (2018)](https://github.com/brendenlake/SCAN/blob/master/README.md).\n",
    "\n",
    "SCAN consists of a set of commands and their corresponding action sequences. These are the actions an agent should perform to execute the commands successfully. The commands and actions are defined compositionally based on primitive verbs (\"*jump*\", \"*walk*\", \"*run*\", \"*turn*\", etc.), modifiers (\"*twice*\", \"*thrice*\", \"*left*\", etc.) and connectors (\"*and*\", \"*after*\", etc.). Here are some examples.\n",
    "\n",
    "|Command | Action sequence |\n",
    "| --- | --- |\n",
    "| IN: jump                |                       OUT: JUMP |\n",
    "| IN: jump left            |                       OUT:  TURN_LEFT JUMP |\n",
    "| IN: jump around right       |                   OUT: TURN_RIGHT JUMP TURN_RIGHT JUMP TURN_RIGHT JUMP TURN_RIGHT JUMP |\n",
    "| IN: turn left twice          |                  OUT: TURN_LEFT TURN_LEFT |\n",
    "| IN: jump thrice               |                 OUT: JUMP JUMP JUMP |\n",
    "| IN: jump opposite left and walk thrice   |      OUT: TURN_LEFT TURN_LEFT JUMP WALK WALK WALK |\n",
    "| IN: jump opposite left after walk around left | OUT: TURN_LEFT WALK TURN_LEFT WALK TURN_LEFT WALK TURN_LEFT WALK TURN_LEFT TURN_LEFT JUMP |\n",
    "\n",
    "In the first part of this lab, we are going to use a random split of the dataset (80% training, 20% test) that is i.i.d. (**independent and identically distributed**). This means that each example is independent from the others and that all examples are drawn from the same probability distribution. In this case, it means that the test set can be expected to exhibit the same properties as the train set.\n",
    "\n",
    "Let's first download the SCAN dataset files from the internet, then load them into a Python list, where each element is a tuple (input sequence, output sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tl_R_KQsDJbg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-20 15:46:47--  https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/simple_split/tasks_train_simple.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3267938 (3.1M) [text/plain]\n",
      "Saving to: ‘train_simple.txt’\n",
      "\n",
      "train_simple.txt    100%[===================>]   3.12M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-10-20 15:46:47 (37.0 MB/s) - ‘train_simple.txt’ saved [3267938/3267938]\n",
      "\n",
      "--2025-10-20 15:46:48--  https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/simple_split/tasks_test_simple.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 812450 (793K) [text/plain]\n",
      "Saving to: ‘test_simple.txt’\n",
      "\n",
      "test_simple.txt     100%[===================>] 793.41K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2025-10-20 15:46:48 (13.4 MB/s) - ‘test_simple.txt’ saved [812450/812450]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download SCAN dataset\n",
    "!wget https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/simple_split/tasks_train_simple.txt -O train_simple.txt\n",
    "!wget https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/simple_split/tasks_test_simple.txt -O test_simple.txt\n",
    "\n",
    "def load_scan_file(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = [line.strip().split(\" OUT: \") for line in f.readlines()]\n",
    "    return [(inp.split()[1:], [x[2:] for x in out.split()]) for inp, out in data]\n",
    "\n",
    "train_data = load_scan_file(\"train_simple.txt\")\n",
    "test_data = load_scan_file(\"test_simple.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFCV4scbsug9"
   },
   "source": [
    "Let's explore some properties of the SCAN dataset.\n",
    "\n",
    "The input command is always a combination of the following words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X11MhsS-ihfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jump', 'left', 'look', 'walk', 'and', 'turn', 'after', 'thrice', 'around', 'right', 'twice', 'opposite', 'run'}\n"
     ]
    }
   ],
   "source": [
    "unique_primitives = set()\n",
    "for in_out in train_data:\n",
    "    unique_primitives.update(in_out[0])\n",
    "print(unique_primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbOy9BEcUVP5"
   },
   "source": [
    "...while the output is a combination of the following actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-kSPyqFTUbdL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RUN', 'LOOK', 'TURN_LEFT', 'TURN_RIGHT', 'JUMP', 'WALK'}\n"
     ]
    }
   ],
   "source": [
    "unique_actions = set()\n",
    "for in_out in train_data:\n",
    "    unique_actions.update(in_out[1])\n",
    "print(unique_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTjdfcx-9MIo"
   },
   "source": [
    "We will also define a helper function to print out specific examples from our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ryT1zaqb9LNK"
   },
   "outputs": [],
   "source": [
    "def print_example(exm):\n",
    "    # for formatting the input and output when printing each sample\n",
    "    input, output = exm\n",
    "    print(f\"IN: {\" \".join(input)}\")\n",
    "    print(f\"OUT: {\" \".join(output)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D9_xXAKaDyg"
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Can you work out the action sequence corresponding to the following commands? Take a look at the examples above to answer this.\n",
    "\n",
    "- IN: *jump opposite left*\n",
    "- IN: *walk around left*\n",
    "- IN: *run opposite right and look left*\n",
    "- IN: *look thrice after jump around right*\n",
    "\n",
    "2. How would you describe the \"algorithm\" you used to map between the tokens in the input sequence and the actions in the output sequence?\n",
    "\n",
    "3. What do you notice?\n",
    "\n",
    "  *   Is there a 1-to-1 mapping between words and actions? NO\n",
    "  *   Does the order of word spans always correspond to the order in which the corresponding actions appear? No\n",
    "\n",
    "4. As a final exercise, assume that the model has seen the two following examples during training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K3pzPTZd1VSN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: jump right twice after walk around right thrice\n",
      "OUT: TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT WALK TURN_RIGHT JUMP TURN_RIGHT JUMP\n",
      "IN: jump opposite right after turn opposite right\n",
      "OUT: TURN_RIGHT TURN_RIGHT TURN_RIGHT TURN_RIGHT JUMP\n"
     ]
    }
   ],
   "source": [
    "print_example(train_data[544])\n",
    "print_example(train_data[1043])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E7ngDe6Giti"
   },
   "source": [
    "During evaluation, the model needs to execute the following command:\n",
    "\n",
    "IN: _jump opposite right after walk around right thrice_\n",
    "\n",
    "How does the test command relate to the two training commands? How can the model take advantage of this to generalise to this unseen command?\n",
    "\n",
    "After completing the exercises with your partner, verify your solutions in the companion file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Srx-y60Hlasp"
   },
   "source": [
    "# 3. Data preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcoJ_aJxwxc4"
   },
   "source": [
    "After familiarising ourselves with the SCAN dataset, we will develop a neural network model that can automatically take in a sequence of commands as input, and produce a sequence of actions as output.\n",
    "\n",
    "To use a neural network to perform this task, we first need to convert both the input and output tokens into a format that can be processed by a neural network, i.e., vector representations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4Q_T6pjzjT5"
   },
   "source": [
    "As you know from week 4, the most widespread approach is to assign each unique token a scalar index and use an `nn.Embedding` layer (from the `torch` library) to learn a dense vector representation for each token, also known as an *embedding*. We will talk more about `nn.Embedding` shortly, but let's focus on assigning token indices for now.\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "As an exercise, fill in the code for the function below, following the specifications in the function descriptor. Also, keep in mind that:\n",
    "- you should ensure that this mapping is deterministic. You can ensure this by sorting your vocabularies (words and actions) alphabetically.\n",
    "- you should reserve 3 indices for special tokens in both vocabularies (see below for an explanation of why this is needed): 0 for `<pad>` (padding), 1 for `<bos>` (beginning of sentence), and 2 for `<eos>` (end of sentence).\n",
    "\n",
    "_Hint_: First create sets of words and actions from the dataset examples, then construct the corresponding dictionaries. In Python, you can update the elements of a `set` with the `update` method and iterate through the indices and elements of a `list` through `enumerate`.\n",
    "\n",
    "Once you've populated the `build_vocab` function, the code uses the resulting vocabularies to map from words/actions to indices (and viceversa) via the `numericalize` function. Note that this function also maps the output sequence into a **tensor**. This is a `torch` class used to efficiently represent (and perform calculations on) numerical arrays of various dimensions and sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JJ3O2_pVZmHk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "IN: ['jump', 'opposite', 'right', 'twice', 'and', 'turn', 'opposite', 'right', 'thrice']\n",
      "OUT: ['TURN_RIGHT', 'TURN_RIGHT', 'JUMP', 'TURN_RIGHT', 'TURN_RIGHT', 'JUMP', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT']\n",
      "Indices:\n",
      "IN: tensor([ 6,  9, 10, 14,  4, 13,  9, 10, 12])\n",
      "OUT: tensor([7, 7, 3, 7, 7, 3, 7, 7, 7, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(pairs):\n",
    "    '''\n",
    "    This function takes in:\n",
    "    -  pairs: the list of (input, output) tuples in the training set\n",
    "    and returns four dictionaries:\n",
    "    - input_w2i: input word to index\n",
    "    - input_i2w: index to input word\n",
    "    - output_w2i: output word to index\n",
    "    - output_i2w: index to output word\n",
    "    '''\n",
    "    ################\n",
    "    # YOUR CODE HERE\n",
    "    ################\n",
    "    input_word_set = set()\n",
    "    output_word_set = set()\n",
    "    for input, output in pairs:\n",
    "        input_word_set.update(input)\n",
    "        output_word_set.update(output)\n",
    "    input_w2i = {w:i+3 for i, w in enumerate(sorted(input_word_set))}\n",
    "    output_w2i = {w:i+3 for i, w in enumerate(sorted(output_word_set))}\n",
    "    input_w2i[\"<pad>\"] = 0\n",
    "    input_w2i[\"<bos>\"] = 1\n",
    "    input_w2i[\"<eos>\"] = 2\n",
    "    output_w2i[\"<pad>\"] = 0\n",
    "    output_w2i[\"<bos>\"] = 1\n",
    "    output_w2i[\"<eos>\"] = 2\n",
    "    \n",
    "    input_i2w = {i:w for i,w in input_w2i.items() }\n",
    "    output_i2w = {w:i for i, w in output_w2i.items()}\n",
    "    return input_w2i, input_i2w, output_w2i, output_i2w\n",
    "input_w2i, input_i2w, output_w2i, output_i2w = build_vocab(train_data)\n",
    "\n",
    "def numericalize(seq, vocab):\n",
    "    # maps a token to its corresponding unique index\n",
    "    return torch.tensor([vocab[w] for w in seq])\n",
    "\n",
    "in_seq, out_seq = train_data[0]\n",
    "\n",
    "print('Original:')\n",
    "print('IN:', in_seq)\n",
    "print('OUT:', out_seq)\n",
    "\n",
    "print('Indices:')\n",
    "print('IN:', numericalize(in_seq, input_w2i))\n",
    "print('OUT:', numericalize(out_seq, output_w2i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6FvY_nJU9Bd"
   },
   "source": [
    "The three special tokens added to the input and output vocabularies have some special purposes:\n",
    "\n",
    "**\\<eos>**: marks the *end of sequence*. It tells the encoder when the input sequence is finished, and tells the decoder when to stop generating output.\n",
    "\n",
    "**\\<bos>**: marks the *beginning of sequence*. It is used only for the decoder side to signal the beginning of decoding.\n",
    "\n",
    "**\\<pad>**: used for *padding* sequences to a uniform length so that they can be processed in batches.\n",
    "\n",
    "*These tokens don’t appear in the original SCAN commands or actions, but they’re essential for training and evaluating sequence models properly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV_Sb_PrS5Ec"
   },
   "source": [
    "# 4. Dataloader and batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScZ40wd7a9XF"
   },
   "source": [
    "Next, let's define `SCANDataset`, a custom Python class to represent our **dataset** (inheriting from `torch.utils.data.Dataset`). Given a sample index, the dataset will return an input-output sequence mapped to the corresponding token indices via `numericalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ne6N3A6KVpg_"
   },
   "outputs": [],
   "source": [
    "class SCANDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.data = data\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp, out = self.data[idx]\n",
    "        input_seq = numericalize(inp + ['<eos>'], self.input_vocab)\n",
    "        target_seq = numericalize(out + ['<eos>'], self.output_vocab)\n",
    "        return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMWN7UbNRl5c"
   },
   "source": [
    "**Batching** is the process of grouping multiple examples together and processing them in parallel during training.\n",
    "Instead of updating the model parameters after seeing just one example at a time, we update them after computing the average loss across a batch of examples.\n",
    "This leads to faster training and more stable gradient estimates.\n",
    "\n",
    "However, in sequence-to-sequence tasks, input and output sequences often have variable lengths.\n",
    "This makes batching challenging, because vectors in a batch must be the same shape in order to stack them together into a matrix.\n",
    "This is where `collate_fn` comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaevumDUR0L0"
   },
   "source": [
    "`collate_fn` is a function that specifies how to combine individual examples into a batch. It is passed to the `DataLoader`, and it handles:\n",
    "\n",
    "- Padding sequences to the same length, which is the maximum length of any sequence in that batch (so they can be stacked into a matrix).\n",
    "\n",
    "- Keeping track of original lengths, which is important for models like RNNs to avoid wasting computation on pad tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qQDyXZKIRxBG"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    # we need to keep track of the lengths of the input sequences\n",
    "    input_lengths = [len(seq) for seq in inputs]\n",
    "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=input_w2i[\"<pad>\"])\n",
    "    targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=output_w2i[\"<pad>\"])\n",
    "    return inputs, targets, input_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjl_ZOw9eB5I"
   },
   "source": [
    "We then use `collate_fn` to create instances of dataloaders for both the train and test splits. It is worth noting that:\n",
    "\n",
    "- The value of `BATCH_SIZE` is usually a power of 2. The choice represents a trade-off between high values (high memory load, more stable gradients) and low values (low memory load, less stable gradients).\n",
    "- We shuffle the training data loader to make sure that each batch is a random sample. Technical note: this guarantees that the gradient estimate we obtain on a single batch of examples is unbiased with respect to the true gradient for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vXkU0xbs1B8j"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = SCANDataset(train_data, input_w2i, output_w2i)#将字符转为vector\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = SCANDataset(test_data, input_w2i, output_w2i)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXv2S8AbUzLl"
   },
   "source": [
    "Here are a few example batches from the train_loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UisBFsIzSVe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor (padded) has shape: torch.Size([32, 10]) \n",
      "\n",
      "This means there are 32 training samples (input sequences), with all the sequences padded to 10 tokens as the max length\n",
      "\n",
      "Below is the first batch of input sequences:\n",
      "\n",
      "tensor([[ 6,  9, 10, 12,  3,  6,  9, 10, 12,  2],\n",
      "        [13,  5, 10,  4, 11,  2,  0,  0,  0,  0],\n",
      "        [ 8,  9, 10, 14,  4, 15,  5, 10, 14,  2],\n",
      "        [ 8, 10, 14,  3, 15,  5, 10, 12,  2,  0],\n",
      "        [ 8,  9,  7, 12,  3,  8,  2,  0,  0,  0],\n",
      "        [13,  9, 10,  4,  6,  9,  7, 12,  2,  0],\n",
      "        [11,  9, 10,  4, 13,  5, 10,  2,  0,  0],\n",
      "        [15,  5,  7, 14,  4,  8,  9,  7,  2,  0],\n",
      "        [11,  5, 10, 14,  3, 11,  9,  7, 14,  2],\n",
      "        [15,  9,  7, 14,  4, 15, 14,  2,  0,  0],\n",
      "        [ 6,  5,  7, 14,  4, 11,  9, 10,  2,  0],\n",
      "        [ 8,  7, 12,  4, 13, 10,  2,  0,  0,  0],\n",
      "        [11,  7,  3, 13,  5,  7, 14,  2,  0,  0],\n",
      "        [ 6,  9, 10,  4, 11,  9, 10,  2,  0,  0],\n",
      "        [ 6,  7, 12,  3, 13,  5, 10, 14,  2,  0],\n",
      "        [ 6,  3,  6,  9,  7, 12,  2,  0,  0,  0],\n",
      "        [13,  5,  7, 14,  4, 11, 10, 14,  2,  0],\n",
      "        [ 8,  9, 10, 14,  3, 13,  5,  7,  2,  0],\n",
      "        [13,  9,  7, 12,  3, 11,  5, 10, 12,  2],\n",
      "        [ 8,  7,  3, 13,  5,  7, 12,  2,  0,  0],\n",
      "        [11,  9, 10,  3, 15, 12,  2,  0,  0,  0],\n",
      "        [13,  9,  7, 14,  4,  8,  9, 10, 12,  2],\n",
      "        [ 6, 10,  4, 15,  9, 10, 12,  2,  0,  0],\n",
      "        [15,  5, 10,  3,  8,  5,  7, 14,  2,  0],\n",
      "        [15, 10,  4, 13,  5, 10, 14,  2,  0,  0],\n",
      "        [ 6,  5,  7,  4, 13,  5, 10, 12,  2,  0],\n",
      "        [11,  9,  7, 14,  3, 11, 14,  2,  0,  0],\n",
      "        [13, 10, 12,  3,  8, 14,  2,  0,  0,  0],\n",
      "        [ 8,  9,  7, 12,  4, 11,  5, 10, 12,  2],\n",
      "        [ 6,  5,  7, 12,  4, 13,  7, 14,  2,  0],\n",
      "        [ 8, 10,  4, 15,  7,  2,  0,  0,  0,  0],\n",
      "        [13,  9, 10, 14,  4,  8,  9, 10, 14,  2]]) \n",
      "\n",
      "(recall 0 is the index for the <pad> token)\n",
      "\n",
      "Actual lengths of the 32 input sequences: [10, 6, 10, 9, 7, 9, 8, 9, 10, 8, 9, 7, 8, 8, 9, 7, 9, 9, 10, 8, 7, 10, 8, 9, 8, 9, 8, 7, 10, 9, 6, 10] \n",
      "\n",
      "Output tensor (padded) has shape: torch.Size([32, 34]) \n",
      "\n",
      "This means there are 32 training samples (output sequences), with all the sequences padded to 34 tokens as the max length\n",
      "\n",
      "Below is the first batch of output sequence:\n",
      "\n",
      "tensor([[7, 7, 3,  ..., 0, 0, 0],\n",
      "        [7, 7, 7,  ..., 0, 0, 0],\n",
      "        [7, 7, 4,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [6, 3, 6,  ..., 0, 0, 0],\n",
      "        [7, 4, 6,  ..., 0, 0, 0],\n",
      "        [7, 7, 7,  ..., 0, 0, 0]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs, targets, input_lengths = next(iter(train_loader))\n",
    "\n",
    "print(\"Input tensor (padded) has shape:\", inputs.shape, \"\\n\")\n",
    "print(f'This means there are {inputs.shape[0]} training samples (input sequences), with all the sequences padded to {inputs.shape[1]} tokens as the max length\\n')\n",
    "print('Below is the first batch of input sequences:\\n')\n",
    "print(inputs, \"\\n\")\n",
    "print('(recall 0 is the index for the <pad> token)\\n')\n",
    "print(\"Actual lengths of the 32 input sequences:\", input_lengths, \"\\n\")\n",
    "print(\"Output tensor (padded) has shape:\", targets.shape, \"\\n\")\n",
    "print(f'This means there are {targets.shape[0]} training samples (output sequences), with all the sequences padded to {targets.shape[1]} tokens as the max length\\n')\n",
    "print('Below is the first batch of output sequence:\\n')\n",
    "print(targets, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cu8G5w74cu_w"
   },
   "source": [
    "# 5. Sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VusYKtOqLGSd"
   },
   "source": [
    "Let's start implementing in `torch` our recurrent model, which consists of an encoder and a decoder:\n",
    "\n",
    "- the **encoder** maps the input sequence of words into a sequence of hidden representations.\n",
    "- the **decoder** maps the sequence of hidden representations into a sequence of actions.\n",
    "\n",
    "We will implement a kind of recurrent network called a Gated Recurrent Unit (GRU; [Cho et al. 2014](https://arxiv.org/pdf/1406.1078)). In comparison with vanilla RNNs, GRUs have learnable gates that stabilise learning by avoiding the risk of gradient vanishing and explosion.\n",
    "\n",
    "The encoder (and the decoder) will consist of a class inheriting from `nn.Module` (via `super().__init__()`): this way, this class will automatically keep track of trainable parameters and their gradients. Both classes contain two methods:\n",
    "\n",
    "`__init__`: This method defines the architecture of the model by specifying each layer within the model. Each layer is initialized with the appropriate input and output dimensions (and possibly other keyword arguments):\n",
    "\n",
    "- An `Embedding` layer maps token indices (with `vocab_size` as the size of the vocabulary) to dense vector representations with dimensionality `hidden_size`.\n",
    "\n",
    "- In the `GRU` layer, the first `hidden_size` indicates the size of each input vector (which is the output of the embedding layer). The second `hidden_size` specifies the size of the GRU's hidden state. These two values are identical in our implementation, but they don't necessarily have to be the same. `num_layers=2` stacks two `GRU` layers, allowing the model to capture more complex temporal dependencies.\n",
    "\n",
    "\n",
    "`forward`: This method outlines the computation that occurs when data is passed through the layers within the model to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0CLd8077rVKd"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      hidden_size)\n",
    "        self.rnn = nn.GRU(input_size=hidden_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=2,\n",
    "                          batch_first=True)\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        # input shape: [batch_size, seq_len]\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded shape: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # See note below on packing\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded,\n",
    "            lengths,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        x, hidden = self.rnn(packed)\n",
    "        # hidden shape: [num_layers, batch_size, hidden_size]\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1pL4MRZd74M"
   },
   "source": [
    "## Note on Packing\n",
    "\n",
    "RNNs, by default, will process the padding tokens as a normal input token unless told otherwise — which wastes computation and add noise to the training.\n",
    "\n",
    "`pack_padded_sequence` tells the RNN to skip the padding tokens and only compute over the actual (unpadded) content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DvlCEWhavGF"
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "Now implement the `__init__` method of the `Decoder`. Remember to add:\n",
    "\n",
    "- an `Embedding` layer, to embed the sequence of decoded output actions.\n",
    "- 2 `GRU` layers.\n",
    "- a `Linear` layer (used only in the decoder), which projects vectors of dimensionality `hidden_size` back to `vocab_size` to map hidden states to output actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FC5rONVW_0z9"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        ################\n",
    "        # YOUR CODE HERE\n",
    "        ################\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      hidden_size)\n",
    "        self.rnn = nn.GRU(input_size = hidden_size, \n",
    "                          hidden_size= hidden_size, \n",
    "                          num_layers=2,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size,\n",
    "                             vocab_size)\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: [batch_size, 1]\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded shape: [batch_size, 1, hidden_size]\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # hidden shape: [batch_size, 1, hidden_size]\n",
    "        output = self.out(output.squeeze(1))\n",
    "        # output shape: [batch_size, vocab_size]\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mIpYQhijaRV"
   },
   "source": [
    "# 6. Training the model\n",
    "\n",
    "We can create instances of an encoder and a decoder with the following specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8edgbCYFaetP"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "\n",
    "example_encoder = Encoder(len(input_w2i), HIDDEN_SIZE)\n",
    "example_decoder = Decoder(len(output_w2i), HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HufQmsnSjtLH"
   },
   "source": [
    "We can check the layers inside the encoder and the decoder with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "F34t3264joOZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(16, 200)\n",
       "  (rnn): GRU(200, 200, num_layers=2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "bhcxyr3kjnSs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(9, 200)\n",
       "  (rnn): GRU(200, 200, num_layers=2, batch_first=True)\n",
       "  (out): Linear(in_features=200, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqmW6576z_j-"
   },
   "source": [
    "We are now ready to train our GRU encoder-decoder on SCAN!\n",
    "\n",
    "We will use `wandb` to help us keep track of the important metrics, such as the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ZpZYi-tU305d"
   },
   "outputs": [],
   "source": [
    "def train_model(run_name, num_epochs, learning_rate, hidden_units=200):\n",
    "    # Initialize wandb to track the experiment metrics\n",
    "    wandb.init(project=\"scan-seq2seq\", name=run_name)\n",
    "\n",
    "    # Initialise your encoder-decoder GRU\n",
    "    encoder = Encoder(len(input_w2i), hidden_units)\n",
    "    decoder = Decoder(len(output_w2i), hidden_units)\n",
    "    wandb.watch(encoder)\n",
    "    wandb.watch(decoder)\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = SCANDataset(train_data, input_w2i, output_w2i)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    # Use the Adam optimizer and a cross-entropy loss\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=output_w2i[\"<pad>\"])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        # For every example,\n",
    "        for inputs, targets, lengths in tqdm(loader):\n",
    "            # remove any gradients currently stored in the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # encode the input into a sequence of hidden states\n",
    "            encoder_output = encoder(inputs, lengths)\n",
    "\n",
    "            # initialize the decoder input as a BOS token for the entire batch\n",
    "            decoder_input = torch.full(\n",
    "                (targets.size(0),),\n",
    "                output_w2i[\"<bos>\"],\n",
    "                dtype=torch.long,\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            # use the last hidden state of the encoder to initialize the hidden state of the decoder\n",
    "            decoder_hidden = encoder_output\n",
    "\n",
    "            # for every time step,\n",
    "            loss = 0\n",
    "            for t in range(targets.size(1)):\n",
    "                # decode an action\n",
    "                output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # calculate the loss\n",
    "                loss += loss_fn(output, targets[:, t])\n",
    "                # update the decoder input via \"teacher forcing\"\n",
    "                decoder_input = targets[:, t].unsqueeze(1)\n",
    "\n",
    "            # perform a step of gradient descent by\n",
    "            # 1) calculating the gradients for all trainable parameters via backpropagation\n",
    "            loss.backward()\n",
    "            # 2) updating the parameter values based on the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # track the total loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        wandb.log({\"loss\": total_loss / len(loader)})\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    # return the trained encoder and decoder\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZDykUvVaBn8"
   },
   "source": [
    "Now we can run the `train_model` function.\n",
    "Note that usually, we would save the **checkpoint** of a model (i.e., the model state including its current parameter values) every few epochs during training; however, here we only return the model state after final epoch in this case as both the model and the data are quite small.\n",
    "\n",
    "When running the code below, you will be prompted to log into Weights & Biases (`wandb`), and will need to create an account if you don't already have one.\n",
    "Follow the instructions to copy and paste the API key: after verifying your email, make sure to select \"Academic\" when creating your account. Skip the creation of an organization profile, then choose \"Models\" when asked \"What do you want to try first?\".\n",
    "\n",
    "Each training run would take around 5-10 minutes to run on a CPU.\n",
    "While the model is running, you should start solving Exercise 4.1, 4.2, and 4.3 below. From time to time, check the loss logged during the training run at the link following `View run at`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TK8Wxh7HumO0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">5-0.001</strong> at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/qxfusudz' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/qxfusudz</a><br> View project at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251020_165709-qxfusudz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/ANLP/ANLP_labs/lab_3/wandb/run-20251020_170037-sdwnti8m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/sdwnti8m' target=\"_blank\">5-0.001</a></strong> to <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/sdwnti8m' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/sdwnti8m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [01:30<00:00,  5.81it/s]\n",
      "100%|██████████| 523/523 [01:29<00:00,  5.88it/s]\n",
      "100%|██████████| 523/523 [01:29<00:00,  5.86it/s]\n",
      "100%|██████████| 523/523 [01:27<00:00,  5.96it/s]\n",
      "100%|██████████| 523/523 [01:27<00:00,  5.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.32432</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">5-0.001</strong> at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/sdwnti8m' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/sdwnti8m</a><br> View project at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251020_170037-sdwnti8m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "lr = 0.001\n",
    "gru_encoder, gru_decoder = train_model(f\"{n_epochs}-{lr}\", n_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb2q0_SObfK0"
   },
   "source": [
    "## Exercise 4\n",
    "\n",
    "1. Which different hyperparameter settings could you explore to further enhance model performance in our code, in terms of optimization（lr batchsize） and model architecture（layer hidden units）?\n",
    "2. In the code above, we are backpropagating after recurring across the entire target sequence (rather than after each step): which ramifications may this have for the model's gradients? vanishing and exploded\n",
    "3. The `train_model` function uses \"teacher forcing\". Can you explain what teacher forcing is and why it is used in training sequence-to-sequence models?\n",
    "4. Based on the loss profile, do you think we need to train more epochs? What other information can you use to decide when to stop training?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXdcPTUh01Iw"
   },
   "source": [
    "# 7. Evaluating the model\n",
    "\n",
    "We can evaluate the performance of the trained sequence-to-sequence model using both qualitative and quantitative methods:\n",
    "1. **Qualitative Evaluation**.\n",
    "\n",
    "We inspect the model’s predictions on selected test examples to assess whether it produces outputs that are:\n",
    "\n",
    "- Syntactically well-formed (e.g., following the correct command structure)\n",
    "\n",
    "- Semantically correct (e.g., executing the intended action)\n",
    "\n",
    "This manual analysis helps reveal specific patterns in the model’s successes and failures, such as whether it correctly handles modifiers like \"*twice*\" or \"*around*\" right.\n",
    "\n",
    "2. **Quantitative Evaluation**.\n",
    "\n",
    "We use standard automatic metrics to assess performance across the test set:\n",
    "\n",
    "- Exact Match (Accuracy):\n",
    "The proportion of test examples for which the model’s entire output sequence exactly matches the ground-truth (aka gold-standard or target) sequence.\n",
    "\n",
    "- n-gram overlap (BLEU):\n",
    "Calculates how many short subsequences (n-grams) overlap between the prediction and the ground truth, capturing partial correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "P86C8-LhubCR"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(encoder, decoder, dataset, max_len=50):\n",
    "    sequences_to_evaluate = []\n",
    "\n",
    "    # load test data\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # switch to evaluation mode, which disables train-time behaviors like dropout\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # for each test example:\n",
    "    for inputs, targets, lengths in tqdm(data_loader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # encode the input sequence\n",
    "            encoder_output = encoder(inputs, lengths)\n",
    "\n",
    "            # initialize the decoder input as a BOS token\n",
    "            decoder_input = torch.tensor(\n",
    "                [[output_w2i[\"<bos>\"]]],\n",
    "            )  # shape (1,1)\n",
    "\n",
    "            # use the last hidden state of the encoder to initialize the hidden state of the decoder\n",
    "            decoder_hidden = encoder_output\n",
    "\n",
    "            predicted_tokens = []\n",
    "\n",
    "            # for every time step,\n",
    "            for _ in range(max_len):\n",
    "                # get the most likely next action\n",
    "                output_logits, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                top1 = output_logits.argmax(1).item()\n",
    "\n",
    "                # stop generation when an EOS token is generated by the model\n",
    "                if top1 == output_w2i[\"<eos>\"]:\n",
    "                    break\n",
    "\n",
    "                predicted_tokens.append(output_i2w[top1])\n",
    "\n",
    "                # update decoder input\n",
    "                decoder_input = torch.tensor([[top1]])\n",
    "\n",
    "            # get ground truth sequence (remove <eos> and <pad>)\n",
    "            reference_tokens = [\n",
    "                output_i2w[idx.item()]\n",
    "                for idx in targets[0]\n",
    "                if idx.item() not in (output_w2i[\"<eos>\"], output_w2i[\"<pad>\"])\n",
    "            ]\n",
    "\n",
    "            sequences_to_evaluate.append((predicted_tokens, reference_tokens))\n",
    "\n",
    "    return sequences_to_evaluate\n",
    "\n",
    "def exact_match(sequences):\n",
    "    total_exact_match = 0\n",
    "\n",
    "    for predicted_tokens, reference_tokens in sequences:\n",
    "      total_exact_match += int(predicted_tokens == reference_tokens)\n",
    "\n",
    "    exact_match_accuracy = total_exact_match / len(sequences)\n",
    "    print(f\"Exact match accuracy: {exact_match_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjRhdqXks7iB"
   },
   "source": [
    "Now let's get the model predictions and evaluate their exact match with the corresponding references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9i-V4pNB1B8o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4182/4182 [00:36<00:00, 113.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match accuracy: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sequences = evaluate_model(gru_encoder, gru_decoder, test_dataset, max_len=50)\n",
    "exact_match(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFiSOeqApxnc"
   },
   "source": [
    "## Exercise 5\n",
    "\n",
    "1. Can you analyse the errors the RNN is making in a qualitative way? Review a dozen pairs of `sequences` where there is no exact match and check what's wrong with the output sequences.\n",
    "2. Exact match is excessively strict as it requires that the actions sequences are identical. Another more fine-grained evaluation metric would compute the n-gram overlap between the target and predicted action sequences. Use [BLEU from `evaluate`](https://huggingface.co/spaces/evaluate-metric/bleu) to implement this metric and evaluate the model predictions. Make sure to read the (short) documentation in the link. *Hints*: you will need to `load` the metric, prepare the predictions and references in the right format, then `compute` the metric on these sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP']\n",
      "Reference: ['TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'TURN_LEFT', 'WALK', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP', 'TURN_LEFT', 'JUMP']\n",
      "Predicted: ['TURN_RIGHT', 'TURN_RIGHT', 'JUMP', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN']\n",
      "Reference: ['TURN_RIGHT', 'TURN_RIGHT', 'JUMP', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN', 'TURN_RIGHT', 'RUN']\n",
      "Predicted: ['TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT']\n",
      "Reference: ['TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT', 'TURN_RIGHT']\n"
     ]
    }
   ],
   "source": [
    "def print_wrong(sequences):\n",
    "    count = 0\n",
    "    for predicted_tokens, reference_tokens in sequences:\n",
    "        if predicted_tokens != reference_tokens:\n",
    "            print(f\"Predicted: {predicted_tokens}\\nReference: {reference_tokens}\")\n",
    "            count += 1\n",
    "        if count == 3:\n",
    "          break\n",
    "\n",
    "print_wrong(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50002f07036e4579a896b324283bb0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fb8d661eff4d40872bdda9231a079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b43fd0a91b4bf3b86bf4e8efc60d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.988\n"
     ]
    }
   ],
   "source": [
    "def evaluate_bleu(sequences):\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    all_predictions = [\" \".join(x) for (x, y) in sequences]\n",
    "    all_references = [\" \".join(y) for (x, y) in sequences]\n",
    "\n",
    "    bleu_results = bleu.compute(predictions=all_predictions, references=all_references)\n",
    "    print(f\"BLEU score: {bleu_results['bleu']:.3f}\")\n",
    "\n",
    "evaluate_bleu(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2RKYiidcZfJ"
   },
   "source": [
    "# 8. Out-of-distribution (OOD) generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F6pcmLgNhKV"
   },
   "source": [
    "Now we look at whether the GRU model can generalize outside of the training domain. For this, we look at a different training-test split, where the output sequences in the test set are all longer than the ones in the training set. This is a case of **out-of-distribution (OOD) generalization**, where the test data are not from the same distribution as the train data (hence, they are not i.i.d.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "E-00cIBOlPq2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-20 17:53:07--  https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/length_split/tasks_train_length.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2723418 (2.6M) [text/plain]\n",
      "Saving to: ‘train_length.txt’\n",
      "\n",
      "train_length.txt    100%[===================>]   2.60M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-10-20 17:53:07 (33.2 MB/s) - ‘train_length.txt’ saved [2723418/2723418]\n",
      "\n",
      "--2025-10-20 17:53:08--  https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/length_split/tasks_test_length.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1356970 (1.3M) [text/plain]\n",
      "Saving to: ‘test_length.txt’\n",
      "\n",
      "test_length.txt     100%[===================>]   1.29M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2025-10-20 17:53:08 (19.4 MB/s) - ‘test_length.txt’ saved [1356970/1356970]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download SCAN dataset\n",
    "!wget https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/length_split/tasks_train_length.txt -O train_length.txt\n",
    "!wget https://raw.githubusercontent.com/brendenlake/SCAN/refs/heads/master/length_split/tasks_test_length.txt -O test_length.txt\n",
    "\n",
    "new_train_data = load_scan_file(\"train_length.txt\")\n",
    "new_test_data = load_scan_file(\"test_length.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qxjtu3UT5GMs"
   },
   "source": [
    "Let's inspect the distributions of lengths in the training and test sets of this data split to study how they differ. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HG9Iojj58Vo_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUtBJREFUeJzt3XlcVdX+//H3kVEFcUARFAE1FTTT4GZgXDUVQzM1LUwz5yIsBxq+kppDKWpmZDmkOdS9OXTTRtEkUyulDBQrs+6tVEghRFM0ExT2748enF9HQDm4CYnX8/E4jwdnnbXX/uzD9sS7tc/aFsMwDAEAAAAArkmNyi4AAAAAAP4OCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwD+liwWS5keO3fuvOZ9nT9/XjNmzLBrrIyMDMXExKhVq1aqWbOm6tevrxtvvFFjx45VRkaG3TV8++23mjFjho4cOWLXdp9//rnuueceeXt7y9nZWY0bN9agQYOUnJxsdw1/NmfOHL3zzjvXNEZZHT9+XDNmzFBaWlqZ+u/cuVMWi0VvvfVWxRZWTlc6n2bMmCGLxaKcnJxyjT1ixAib87927dry9/fXXXfdpdWrVysvL6/YNl27dlXXrl3t2k95z8fL93XkyBFZLBYtWLDArnGuprTzs+jcMONzAUD15FjZBQBARbg8HDzzzDPasWOHPv74Y5v2oKCga97X+fPnNXPmTEkq0x+hP//8s26++WbVrVtXjz32mFq3bq0zZ87o22+/1ZtvvqmffvpJvr6+dtXw7bffaubMmeratav8/f3LtM1LL72kiRMn6pZbbtH8+fPl5+en9PR0LV68WLfddptefPFFPfLII3bVUWTOnDkaNGiQ+vfvX67t7XH8+HHNnDlT/v7+6tChQ4Xvr6LZez7Zq2bNmtZ/B7///rsyMjK0ZcsWjR07Vs8//7y2bt2qpk2bWvsvWbLE7n2U53ws777Ko7Tz8+abb1ZycrIpnwsAqifCFYC/pVtvvdXmecOGDVWjRo1i7ZVhxYoVysnJ0d69exUQEGBt79+/v5566ikVFhZWeA27d+/WxIkT1bt3b7399ttydPz//zkYPHiwBgwYoAkTJqhjx47q3LlzhdeDv05J/w4eeOABjRw5UnfeeacGDRqkzz//3PraXxE0zp8/r1q1alV6qKlTp8518RkBoOriskAA1VZ+fr6effZZtWnTRi4uLmrYsKFGjhypEydO2PT7+OOP1bVrVzVo0EA1a9ZUs2bNNHDgQJ0/f15HjhxRw4YNJUkzZ860Xm41YsSIUvd78uRJ1ahRQ40aNSrx9Ro1bD+aU1JSdNddd6l+/fpydXVVx44d9eabb1pfX7Nmje655x5JUrdu3aw1rFmzptQa4uPjZbFYtHTpUptgJUmOjo5asmSJLBaL5s6da20fMWJEibMQRZeqFbFYLPrtt9/02muvWWspmoFZs2aNLBaLkpKSNHLkSNWvX1+1a9dW37599dNPP9mM6+/vX+L7+OdLx3bu3Kl//OMfkqSRI0da9zdjxoxSj72ssrKy9NBDD6lp06ZydnZWQECAZs6cqUuXLln7/PmytYULFyogIEBubm4KDQ21CShFVqxYoVatWsnFxUVBQUFau3atzfta1vPpl19+0X333ScPDw95eXlp1KhROnPmzDUdb0REhMaOHasvvvhCn3zyibW9pMsCly5dqptuuklubm5yd3dXmzZt9NRTT0m6+vnYtWtXtWvXTp988onCwsJUq1YtjRo1qtR9SVJhYaFmz56tZs2aydXVVSEhIdq+fbtNHzPOz9IuC3zvvfcUGhqqWrVqyd3dXT179iw2O160n4MHD5r+uwFQdRCuAFRLhYWF6tevn+bOnashQ4Zo8+bNmjt3rpKSktS1a1f9/vvvkv74Y7dPnz5ydnbWqlWrtHXrVs2dO1e1a9dWfn6+vL29tXXrVknS6NGjlZycrOTkZE2bNq3UfYeGhqqwsFB33323PvzwQ+Xm5pbad8eOHercubNOnz6tZcuW6d1331WHDh0UFRVl/WO1T58+mjNnjiRp8eLF1hr69OlT4pgFBQXasWOHQkJCbC7/+jNfX18FBwfr448/VkFBwVXfzz9LTk5WzZo11bt3b2stl1/uNXr0aNWoUUNr165VQkKC9u7dq65du+r06dN27evmm2/W6tWrJUlTp0617m/MmDF2jXO5rKws3XLLLfrwww/19NNPa8uWLRo9erTi4+M1duzYYv0XL16spKQkJSQk6I033tBvv/2m3r172/xRvXz5cj344INq3769Nm3apKlTp2rmzJk2f8iX9XwaOHCgWrVqpY0bN2ry5Mlau3atJk2adE3HLEl33XWXJNmEq8utX79eMTEx6tKli95++2298847mjRpkn777TdJZTsfMzMzdf/992vIkCFKTExUTEzMFet6+eWXtXXrViUkJOjf//63atSoocjIyHJ9N7As5+efrV27Vv369VOdOnW0bt06rVy5Ur/++qu6du2qzz77rFj/ivrdAKgiDACoBoYPH27Url3b+nzdunWGJGPjxo02/b788ktDkrFkyRLDMAzjrbfeMiQZaWlppY594sQJQ5Ixffr0MtVSWFhoPPTQQ0aNGjUMSYbFYjECAwONSZMmGYcPH7bp26ZNG6Njx47GxYsXbdrvvPNOw9vb2ygoKDAMwzD+85//GJKMHTt2XHX/WVlZhiRj8ODBV+wXFRVlSDJ++eUXwzD+eA/9/PyK9Zs+fbpx+X9OateubQwfPrxY39WrVxuSjAEDBti0796925BkPPvss9Y2Pz+/Esfo0qWL0aVLF+vzot/Z6tWrr3g8RXbs2GFIMv7zn/+U2uehhx4y3NzcjKNHj9q0L1iwwJBkHDx40DAMwzh8+LAhybjxxhuNS5cuWfvt3bvXkGSsW7fOMAzDKCgoMBo3bmx06tTJZryjR48aTk5ONu/rlc6novd6/vz5Nu0xMTGGq6urUVhYeMVjv/zfweUOHTpkSDIefvhha9vl7/cjjzxi1K1b94r7udL52KVLF0OSsX379hJf+/O+it5fHx8f4/fff7e25+bmGvXr1zd69Ohhc2zXen4WnRtFdRcUFBg+Pj7GjTfeaP23ZhiGcfbsWaNRo0ZGWFhYsf2U93cD4O+BmSsA1dIHH3ygunXrqm/fvrp06ZL10aFDBzVu3Ng6m9ChQwc5OzvrwQcf1GuvvVbs0rXysFgsWrZsmX766SctWbJEI0eO1MWLF/XCCy+obdu22rVrlyTphx9+0HfffaehQ4dKkk2dvXv3VmZmpr7//vtrrqc0hmFY6zVb0TEVCQsLk5+fn3bs2GH6vsrjgw8+ULdu3eTj42PzvkdGRkqS9XdUpE+fPnJwcLA+b9++vSTp6NGjkqTvv/9eWVlZuvfee222a9asWbm+01Y0w/Tn/V24cEHZ2dl2j/VnRb/zK7nlllt0+vRp3XfffXr33XfLtXJhvXr1dPvtt5e5/9133y1XV1frc3d3d/Xt21effPKJ3TOr9vj+++91/PhxDRs2zOZyXTc3Nw0cOFCff/65zp8/b7NNRf1uAFQNhCsA1dIvv/yi06dPy9nZWU5OTjaPrKws6x+MLVq00EcffaRGjRpp3LhxatGihVq0aKEXX3zxmmvw8/PTww8/rJUrV+p///ufNmzYoAsXLuiJJ56w1ihJjz/+eLEaiy6jKs8ftp6enqpVq5YOHz58xX5HjhxRrVq1VL9+fbv3cTWNGzcuse3kyZOm76s8fvnlF73//vvF3ve2bdtKKv6+N2jQwOa5i4uLJFkvLy06Li8vr2L7Kqntaq62v/IqCoM+Pj6l9hk2bJhWrVqlo0ePauDAgWrUqJE6deqkpKSkMu/H29vbrrpKO1/y8/N17tw5u8ayR9HvraR6fXx8VFhYqF9//dWmvaJ+NwCqBlYLBFAteXp6qkGDBtbvt1zO3d3d+nN4eLjCw8NVUFCglJQU6xLmXl5eGjx4sGk13XvvvYqPj9c333xjrVGS4uLidPfdd5e4TevWre3ej4ODg7p166atW7fq559/LvF7Vz///LNSU1MVGRlpnZFxdXUt8T5I5Ql4WVlZJba1bNnS+vxK+yt6byqKp6en2rdvr9mzZ5f4+pXCR0mK/uAuCsx/VtJ7UVnee+89SVdfAn7kyJEaOXKkfvvtN33yySeaPn267rzzTv33v/+Vn5/fVfdj72xoaeeLs7Oz3NzcJJl7fhYp+r1lZmYWe+348eOqUaOG6tWrV+7xAfz9MHMFoFq68847dfLkSRUUFCgkJKTYo6TQ4uDgoE6dOmnx4sWSpH379kmy//9Ml/SHmiSdO3dOGRkZ1j/cW7durRtuuEEHDhwoscaQkBBrCLS3hri4OBmGoZiYmGKXVRUUFOjhhx+WYRiKi4uztvv7+ys7O9smIOTn5+vDDz8sNr6Li8sVa3njjTdsnu/Zs0dHjx61+aPe399fX331lU2///73v8UuhayImYE777xT33zzjVq0aFHi+25vuGrdurUaN25ss8qjJKWnp2vPnj02bZU105GUlKRXX31VYWFhuu2228q0Te3atRUZGakpU6YoPz9fBw8elGT+MWzatEkXLlywPj979qzef/99hYeHW8O/mednkdatW6tJkyZau3atzSWTv/32mzZu3GhdQRAAijBzBaBaGjx4sN544w317t1bEyZM0C233CInJyf9/PPP2rFjh/r166cBAwZo2bJl+vjjj9WnTx81a9ZMFy5c0KpVqyRJPXr0kPTHLJefn5/effddde/eXfXr15enp2epN0+dPXu2du/eraioKHXo0EE1a9bU4cOH9fLLL+vkyZN67rnnrH1feeUVRUZGqlevXhoxYoSaNGmiU6dO6dChQ9q3b5/+85//SJLatWsn6Y8V6dzd3eXq6qqAgIBilygV6dy5sxISEjRx4kTddttteuSRR9SsWTPrTYS/+OILJSQkKCwszLpNVFSUnn76aQ0ePFhPPPGELly4oEWLFpX4nZcbb7xRO3fu1Pvvvy9vb2+5u7vbBNaUlBSNGTNG99xzjzIyMjRlyhQ1adLEZtW4YcOG6f7771dMTIwGDhyoo0ePav78+dalyou0aNFCNWvW1BtvvKHAwEC5ubnJx8fnqgGopKXSJalLly6aNWuWkpKSFBYWpvHjx6t169a6cOGCjhw5osTERC1btqzUlRZLUqNGDc2cOVMPPfSQBg0apFGjRun06dOaOXOmvL29bb7PY+/5ZK/CwkLrsefl5Sk9PV1btmzRm2++qcDAwGIB8HJjx45VzZo11blzZ3l7eysrK0vx8fHy8PCwLotv7/l4NQ4ODurZs6diY2NVWFioefPmKTc313qzZcnc87NIjRo1NH/+fA0dOlR33nmnHnroIeXl5em5557T6dOnbW5VAACSWC0QQPVQ0ippFy9eNBYsWGDcdNNNhqurq+Hm5ma0adPGeOihh4z//e9/hmEYRnJysjFgwADDz8/PcHFxMRo0aGB06dLFeO+992zG+uijj4yOHTsaLi4uhqQSVyIr8vnnnxvjxo0zbrrpJqN+/fqGg4OD0bBhQ+OOO+4wEhMTi/U/cOCAce+99xqNGjUynJycjMaNGxu33367sWzZMpt+CQkJRkBAgOHg4FDm1fOSk5ONQYMGGV5eXoajo6PRqFEj4+677zb27NlTYv/ExESjQ4cORs2aNY3mzZsbL7/8comrsaWlpRmdO3c2atWqZUiyrgBXtFrgtm3bjGHDhhl169Y1atasafTu3dv6nhcpLCw05s+fbzRv3txwdXU1QkJCjI8//rjYinKG8cfqj23atDGcnJyuunJj0YpwpT2KVoo7ceKEMX78eCMgIMBwcnIy6tevbwQHBxtTpkwxzp07ZxjG/1/N7rnnniu2n5LqWL58udGyZUvD2dnZaNWqlbFq1SqjX79+RseOHW36lXY+Fb3XJ06csOlf9L5evtrk5YYPH25zrDVr1jSaNWtm9O3b11i1apWRl5dXbJvL3+/XXnvN6Natm+Hl5WU4OzsbPj4+xr333mt89dVXNtuVdj526dLFaNu2bYn1lbZa4Lx584yZM2caTZs2NZydnY2OHTsaH374YbHtr/X8vHy1wCLvvPOO0alTJ8PV1dWoXbu20b17d2P37t02fa71dwPg78FiGGVYGggAABOsWbNGI0eO1JdffqmQkJDKLqfSnT59Wq1atVL//v21fPnyyi4HAHCNuCwQAIC/QFZWlmbPnq1u3bqpQYMGOnr0qF544QWdPXtWEyZMqOzyAAAmIFwBAPAXcHFx0ZEjRxQTE6NTp06pVq1auvXWW7Vs2TLrEu8AgKqNywIBAAAAwAQsxQ4AAAAAJiBcAQAAAIAJCFcAAAAAYAIWtChBYWGhjh8/Lnd3d1kslsouBwAAAEAlMQxDZ8+elY+Pj81N30tCuCrB8ePH5evrW9llAAAAALhOZGRkqGnTplfsQ7gqgbu7u6Q/3sA6depUcjUAAAAAKktubq58fX2tGeFKCFclKLoUsE6dOoQrAAAAAGX6uhALWgAAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJjAsbILAPD34T95c4WNfWRunwobGwAAwAzMXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmqPRwtWTJEgUEBMjV1VXBwcH69NNPS+2bmZmpIUOGqHXr1qpRo4YmTpx4xbHXr18vi8Wi/v37m1s0AAAAAFymUsPVhg0bNHHiRE2ZMkX79+9XeHi4IiMjlZ6eXmL/vLw8NWzYUFOmTNFNN910xbGPHj2qxx9/XOHh4RVROgAAAADYqNRwtXDhQo0ePVpjxoxRYGCgEhIS5Ovrq6VLl5bY39/fXy+++KIeeOABeXh4lDpuQUGBhg4dqpkzZ6p58+YVVT4AAAAAWFVauMrPz1dqaqoiIiJs2iMiIrRnz55rGnvWrFlq2LChRo8eXab+eXl5ys3NtXkAAAAAgD0qLVzl5OSooKBAXl5eNu1eXl7Kysoq97i7d+/WypUrtWLFijJvEx8fLw8PD+vD19e33PsHAAAAUD1V+oIWFovF5rlhGMXayurs2bO6//77tWLFCnl6epZ5u7i4OJ05c8b6yMjIKNf+AQAAAFRfjpW1Y09PTzk4OBSbpcrOzi42m1VWP/74o44cOaK+ffta2woLCyVJjo6O+v7779WiRYti27m4uMjFxaVc+wQAAAAAqRJnrpydnRUcHKykpCSb9qSkJIWFhZVrzDZt2ujrr79WWlqa9XHXXXepW7duSktL43I/AAAAABWm0mauJCk2NlbDhg1TSEiIQkNDtXz5cqWnpys6OlrSH5frHTt2TK+//rp1m7S0NEnSuXPndOLECaWlpcnZ2VlBQUFydXVVu3btbPZRt25dSSrWDgAAAABmqtRwFRUVpZMnT2rWrFnKzMxUu3btlJiYKD8/P0l/3DT48ntedezY0fpzamqq1q5dKz8/Px05cuSvLB0AAAAAbFgMwzAqu4jrTW5urjw8PHTmzBnVqVOnsssBqgz/yZsrbOwjc/tU2NgAAAClsScbVPpqgQAAAADwd0C4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABM4FjZBQCS5D95c4WNfWRunwobGwAAACjCzBUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmqPRwtWTJEgUEBMjV1VXBwcH69NNPS+2bmZmpIUOGqHXr1qpRo4YmTpxYrM+KFSsUHh6uevXqqV69eurRo4f27t1bgUcAAAAAAJUcrjZs2KCJEydqypQp2r9/v8LDwxUZGan09PQS++fl5alhw4aaMmWKbrrpphL77Ny5U/fdd5927Nih5ORkNWvWTBERETp27FhFHgoAAACAaq5Sw9XChQs1evRojRkzRoGBgUpISJCvr6+WLl1aYn9/f3+9+OKLeuCBB+Th4VFinzfeeEMxMTHq0KGD2rRpoxUrVqiwsFDbt2+vyEMBAAAAUM1VWrjKz89XamqqIiIibNojIiK0Z88e0/Zz/vx5Xbx4UfXr1y+1T15ennJzc20eAAAAAGCPSgtXOTk5KigokJeXl027l5eXsrKyTNvP5MmT1aRJE/Xo0aPUPvHx8fLw8LA+fH19Tds/AAAAgOqh0he0sFgsNs8NwyjWVl7z58/XunXrtGnTJrm6upbaLy4uTmfOnLE+MjIyTNk/AAAAgOrDsbJ27OnpKQcHh2KzVNnZ2cVms8pjwYIFmjNnjj766CO1b9/+in1dXFzk4uJyzfsEAAAAUH1V2syVs7OzgoODlZSUZNOelJSksLCwaxr7ueee0zPPPKOtW7cqJCTkmsYCAAAAgLKotJkrSYqNjdWwYcMUEhKi0NBQLV++XOnp6YqOjpb0x+V6x44d0+uvv27dJi0tTZJ07tw5nThxQmlpaXJ2dlZQUJCkPy4FnDZtmtauXSt/f3/rzJibm5vc3Nz+2gMEAAAAUG1UariKiorSyZMnNWvWLGVmZqpdu3ZKTEyUn5+fpD9uGnz5Pa86duxo/Tk1NVVr166Vn5+fjhw5IumPmxLn5+dr0KBBNttNnz5dM2bMqNDjAQAAAFB9VWq4kqSYmBjFxMSU+NqaNWuKtRmGccXxikIWAAAAAPyVKn21QAAAAAD4OyBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsfKLgDXJ//Jmyts7CNz+1TY2PaoqGMs7fiqw3taHfB7BAAApWHmCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATmBKuTp8+bcYwAAAAAFBl2R2u5s2bpw0bNlif33vvvWrQoIGaNGmiAwcOmFocAAAAAFQVdoerV155Rb6+vpKkpKQkJSUlacuWLYqMjNQTTzxheoEAAAAAUBU42rtBZmamNVx98MEHuvfeexURESF/f3916tTJ9AIBAAAAoCqwe+aqXr16ysjIkCRt3bpVPXr0kCQZhqGCggJzqwMAAACAKsLumau7775bQ4YM0Q033KCTJ08qMjJSkpSWlqaWLVuaXiAAAAAAVAV2h6sXXnhB/v7+ysjI0Pz58+Xm5ibpj8sFY2JiTC8QAAAAAKoCuy8LdHJy0uOPP64XX3xRHTt2tLZPnDhRY8aMsbuAJUuWKCAgQK6urgoODtann35aat/MzEwNGTJErVu3Vo0aNTRx4sQS+23cuFFBQUFycXFRUFCQ3n77bbvrAgAAAAB7lOs+V//617902223ycfHR0ePHpUkJSQk6N1337VrnA0bNmjixImaMmWK9u/fr/DwcEVGRio9Pb3E/nl5eWrYsKGmTJmim266qcQ+ycnJioqK0rBhw3TgwAENGzZM9957r7744gv7DhIAAAAA7GB3uFq6dKliY2MVGRmp06dPWxexqFu3rhISEuwaa+HChRo9erTGjBmjwMBAJSQkyNfXV0uXLi2xv7+/v1588UU98MAD8vDwKLFPQkKCevbsqbi4OLVp00ZxcXHq3r273bUBAAAAgD3sDlcvvfSSVqxYoSlTpsjBwcHaHhISoq+//rrM4+Tn5ys1NVURERE27REREdqzZ4+9ZVklJycXG7NXr15XHDMvL0+5ubk2DwAAAACwh93h6vDhwzbftSri4uKi3377rczj5OTkqKCgQF5eXjbtXl5eysrKsrcsq6ysLLvHjI+Pl4eHh/VRdB8vAAAAACgru8NVQECA0tLSirVv2bJFQUFBdhdgsVhsnhuGUaytoseMi4vTmTNnrI+i+3gBAAAAQFnZvRT7E088oXHjxunChQsyDEN79+7VunXrFB8fr1dffbXM43h6esrBwaHYjFJ2dnaxmSd7NG7c2O4xXVxc5OLiUu59AgAAAIDdM1cjR47U9OnT9eSTT+r8+fMaMmSIli1bphdffFGDBw8u8zjOzs4KDg5WUlKSTXtSUpLCwsLsLcsqNDS02Jjbtm27pjEBAAAA4GrsnrmSpLFjx2rs2LHKyclRYWGhGjVqVK6dx8bGatiwYQoJCVFoaKiWL1+u9PR0RUdHS/rjcr1jx47p9ddft25TdEniuXPndOLECaWlpcnZ2dl6SeKECRP0z3/+U/PmzVO/fv307rvv6qOPPtJnn31WrhoBAAAAoCzKFa6KeHp6XtPOo6KidPLkSc2aNUuZmZlq166dEhMT5efnJ+mPmwZffs+rPy+mkZqaqrVr18rPz09HjhyRJIWFhWn9+vWaOnWqpk2bphYtWmjDhg3q1KnTNdUKAAAAAFdSpnDVsWPHMi8ysW/fPrsKiImJUUxMTImvrVmzplibYRhXHXPQoEEaNGiQXXUAAAAAwLUoU7jq379/BZcBAAAAAFVbmcLV9OnTK7oOAAAAAKjSyv2dq5SUFB06dEgWi0WBgYEKDg42sy4AAAAAqFLsDlc///yz7rvvPu3evVt169aVJJ0+fVphYWFat26dfH19za4RAAAAAK57dt/natSoUbp48aIOHTqkU6dO6dSpUzp06JAMw9Do0aMrokYAAAAAuO7ZPXP16aefas+ePWrdurW1rXXr1nrppZfUuXNnU4sDAAAAgKrC7pmrZs2a6eLFi8XaL126pCZNmphSFAAAAABUNXaHq/nz5+vRRx9VSkqK9Z5TKSkpmjBhghYsWGB6gQAAAABQFdh9WeCIESN0/vx5derUSY6Of2x+6dIlOTo6atSoURo1apS176lTp8yrFAAAAACuY3aHq4SEhAooAwAAAACqNrvD1fDhwyuiDgAAAACo0sp9E+Hs7GxlZ2ersLDQpr19+/bXXBQAAAAAVDV2h6vU1FQNHz7cem+rP7NYLCooKDCtOAAAAACoKuwOVyNHjlSrVq20cuVKeXl5yWKxVERdAAAAAFCl2B2uDh8+rE2bNqlly5YVUQ8AAAAAVEl23+eqe/fuOnDgQEXUAgAAAABVlt0zV6+++qqGDx+ub775Ru3atZOTk5PN63fddZdpxQEAAABAVWF3uNqzZ48+++wzbdmypdhrLGgBAAAAoLqy+7LA8ePHa9iwYcrMzFRhYaHNg2AFAAAAoLqyO1ydPHlSkyZNkpeXV0XUAwAAAABVkt3h6u6779aOHTsqohYAAAAAqLLs/s5Vq1atFBcXp88++0w33nhjsQUtxo8fb1pxAAAAAFBVlGu1QDc3N+3atUu7du2yec1isRCuAAAAAFRL5bqJMAAAAADAlt3fuQIAAAAAFGf3zJUk/fzzz3rvvfeUnp6u/Px8m9cWLlxoSmEAAAAAUJXYHa62b9+uu+66SwEBAfr+++/Vrl07HTlyRIZh6Oabb66IGgEAAADgumf3ZYFxcXF67LHH9M0338jV1VUbN25URkaGunTponvuuaciagQAAACA657d4erQoUMaPny4JMnR0VG///673NzcNGvWLM2bN8/0AgEAAACgKrA7XNWuXVt5eXmSJB8fH/3444/W13JycsyrDAAAAACqELu/c3Xrrbdq9+7dCgoKUp8+ffTYY4/p66+/1qZNm3TrrbdWRI0AAAAAcN2zO1wtXLhQ586dkyTNmDFD586d04YNG9SyZUu98MILphcIAAAAAFWB3eGqefPm1p9r1aqlJUuWmFoQAAAAAFRFdn/n6qOPPir1tVdeeeWaigEAAACAqsrucFX0Pas/3zz4xIkT6tu3r+Li4kwtDgAAAACqCrvD1SeffKL3339f//jHP3Tw4EFt3rxZ7dq107lz53TgwIGKqBEAAAAArnt2f+eqU6dO2r9/v6KjoxUcHKzCwkI9++yzeuKJJ2SxWCqiRkjyn7y5QsY9MrdPhYwLAAAAVDd2z1xJ0vfff68vv/xSTZs2laOjo7777judP3/e7NoAAAAAoMqwO1zNnTtXoaGh6tmzp7755ht9+eWX2r9/v9q3b6/k5OSKqBEAAAAArnt2h6sXX3xR77zzjl566SW5urqqbdu22rt3r+6++2517dq1AkoEAAAAgOuf3d+5+vrrr+Xp6WnT5uTkpOeee0533nmnaYUBAAAAQFVi98zV5cHqzwIDA6+pGAAAAACoqsocrmrVqqUTJ05Yn99xxx3KzMy0Pv/ll1/k7e1tbnUAAAAAUEWUOVxduHBBhmFYn+/evVu///67TZ8/vw4AAAAA1Um5lmIvDfe5AgAAAFBdmRquAAAAAKC6KnO4slgsNjNTlz8HAAAAgOqszEuxG4ahVq1aWQPVuXPn1LFjR9WoUcP6OgAAAABUV2UOV6tXr67IOgAAAACgSitzuBo+fHiFFLBkyRI999xzyszMVNu2bZWQkKDw8PBS++/atUuxsbE6ePCgfHx89OSTTyo6OtqmT0JCgpYuXar09HR5enpq0KBBio+Pl6ura4UcAwAAAABU6oIWGzZs0MSJEzVlyhTt379f4eHhioyMVHp6eon9Dx8+rN69eys8PFz79+/XU089pfHjx2vjxo3WPm+88YYmT56s6dOn69ChQ1q5cqU2bNiguLi4v+qwAAAAAFRDZZ65qggLFy7U6NGjNWbMGEl/zDh9+OGHWrp0qeLj44v1X7ZsmZo1a6aEhARJUmBgoFJSUrRgwQINHDhQkpScnKzOnTtryJAhkiR/f3/dd9992rt3719zUAAAAACqpUqbucrPz1dqaqoiIiJs2iMiIrRnz54St0lOTi7Wv1evXkpJSdHFixclSbfddptSU1OtYeqnn35SYmKi+vTpU2oteXl5ys3NtXkAAAAAgD3KNHOVm5urOnXqmLrjnJwcFRQUyMvLy6bdy8tLWVlZJW6TlZVVYv9Lly4pJydH3t7eGjx4sE6cOKHbbrtNhmHo0qVLevjhhzV58uRSa4mPj9fMmTOv/aAAAAAAVFtlmrmqV6+esrOzJUm33367Tp8+bVoBl98ryzCMK94/q6T+f27fuXOnZs+erSVLlmjfvn3atGmTPvjgAz3zzDOljhkXF6czZ85YHxkZGeU9HAAAAADVVJlmrtzc3HTy5Ek1atRIO3futF6Cdy08PT3l4OBQbJYqOzu72OxUkcaNG5fY39HRUQ0aNJAkTZs2TcOGDbN+j+vGG2/Ub7/9pgcffFBTpkyx3pfrz1xcXOTi4nLNxwQAAACg+ipTuOrRo4e6deumwMBASdKAAQPk7OxcYt+PP/64TDt2dnZWcHCwkpKSNGDAAGt7UlKS+vXrV+I2oaGhev/9923atm3bppCQEDk5OUmSzp8/XyxAOTg4yDAMbnQMAAAAoMKUKVz9+9//1muvvaYff/xRu3btUtu2bVWrVq1r3nlsbKyGDRumkJAQhYaGavny5UpPT7fetyouLk7Hjh3T66+/LkmKjo7Wyy+/rNjYWI0dO1bJyclauXKl1q1bZx2zb9++WrhwoTp27KhOnTrphx9+0LRp03TXXXfJwcHhmmsGAAAAgJKUKVzVrFnTGnhSUlI0b9481a1b95p3HhUVpZMnT2rWrFnKzMxUu3btlJiYKD8/P0lSZmamzT2vAgIClJiYqEmTJmnx4sXy8fHRokWLrMuwS9LUqVNlsVg0depUHTt2TA0bNlTfvn01e/bsa64XAAAAAEpj932uduzYYf358sUkyiMmJkYxMTElvrZmzZpibV26dNG+fftKHc/R0VHTp0/X9OnTy10TAAAAANirXPe5ev3113XjjTeqZs2aqlmzptq3b69//etfZtcGAAAAAFWG3TNXCxcu1LRp0/TII4+oc+fOMgxDu3fvVnR0tHJycjRp0qSKqBMAAAAArmt2h6uXXnpJS5cu1QMPPGBt69evn9q2basZM2YQrgAAAABUS3ZfFpiZmamwsLBi7WFhYcrMzDSlKAAAAACoauwOVy1bttSbb75ZrH3Dhg264YYbTCkKAAAAAKoauy8LnDlzpqKiovTJJ5+oc+fOslgs+uyzz7R9+/YSQxcAAAAAVAd2z1wNHDhQX3zxhTw9PfXOO+9o06ZN8vT01N69ezVgwICKqBEAAAAArnt2z1xJUnBwsP7973+bXQsAAAAAVFnlus8VAAAAAMAW4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwgd2rBf7222+aO3eutm/fruzsbBUWFtq8/tNPP5lWHAAAAABUFXaHqzFjxmjXrl0aNmyYvL29ZbFYKqIuAAAAAKhS7A5XW7Zs0ebNm9W5c+eKqAcAAAAAqiS7v3NVr1491a9fvyJqAQAAAIAqy+5w9cwzz+jpp5/W+fPnK6IeAAAAAKiS7L4s8Pnnn9ePP/4oLy8v+fv7y8nJyeb1ffv2mVYcAAAAAFQVdoer/v37V0AZAAAAAFC12R2upk+fXhF1AAAAAECVZne4KpKamqpDhw7JYrEoKChIHTt2NLMuAAAAAKhS7A5X2dnZGjx4sHbu3Km6devKMAydOXNG3bp10/r169WwYcOKqBMAAAAArmt2rxb46KOPKjc3VwcPHtSpU6f066+/6ptvvlFubq7Gjx9fETUCAAAAwHXP7pmrrVu36qOPPlJgYKC1LSgoSIsXL1ZERISpxQEAAABAVWH3zFVhYWGx5dclycnJSYWFhaYUBQAAAABVjd3h6vbbb9eECRN0/Phxa9uxY8c0adIkde/e3dTiAAAAAKCqsDtcvfzyyzp79qz8/f3VokULtWzZUgEBATp79qxeeumliqgRAAAAAK57dn/nytfXV/v27VNSUpK+++47GYahoKAg9ejRoyLqAwAAAIAqodz3uerZs6d69uxpZi0AAAAAUGWVKVwtWrRIDz74oFxdXbVo0aIr9mU5dgAAAADVUZnC1QsvvKChQ4fK1dVVL7zwQqn9LBYL4QoAAABAtVSmcHX48OESfwYAAAAA/MHu1QJnzZql8+fPF2v//fffNWvWLFOKAgAAAICqxu5wNXPmTJ07d65Y+/nz5zVz5kxTigIAAACAqsbucGUYhiwWS7H2AwcOqH79+qYUBQAAAABVTZmXYq9Xr54sFossFotatWplE7AKCgp07tw5RUdHV0iRAAAAAHC9K3O4SkhIkGEYGjVqlGbOnCkPDw/ra87OzvL391doaGiFFAkA1ZX/5M0VNvaRuX0qbGygovFvA8D1qMzhavjw4bp06ZIkqUePHmratGmFFQUAAAAAVY1d37lydHRUTEyMCgoKKqoeAAAAAKiS7F7QolOnTtq/f39F1AIAAAAAVVaZLwssEhMTo8cee0w///yzgoODVbt2bZvX27dvb1pxAAAAAFBV2B2uoqKiJEnjx4+3tlksFusS7VwyCAAAAKA6sjtcHT58uCLqAAAAAIAqze5w5efnVxF1AAAAAECVZne4kqQff/xRCQkJOnTokCwWiwIDAzVhwgS1aNHC7PoAAAAAoEqwe7XADz/8UEFBQdq7d6/at2+vdu3a6YsvvlDbtm2VlJRUETUCAAAAwHXP7pmryZMna9KkSZo7d26x9v/7v/9Tz549TSsOAAAAAKoKu2euDh06pNGjRxdrHzVqlL799ltTigIAAACAqsbucNWwYUOlpaUVa09LS1OjRo3sLmDJkiUKCAiQq6urgoOD9emnn16x/65duxQcHCxXV1c1b95cy5YtK9bn9OnTGjdunLy9veXq6qrAwEAlJibaXRsAAAAAlJXdlwWOHTtWDz74oH766SeFhYXJYrHos88+07x58/TYY4/ZNdaGDRs0ceJELVmyRJ07d9Yrr7yiyMhIffvtt2rWrFmx/ocPH1bv3r01duxY/fvf/9bu3bsVExOjhg0bauDAgZKk/Px89ezZU40aNdJbb72lpk2bKiMjQ+7u7vYeKgAAAACUmd3hatq0aXJ3d9fzzz+vuLg4SZKPj49mzJhhc2Phsli4cKFGjx6tMWPGSJISEhL04YcfaunSpYqPjy/Wf9myZWrWrJkSEhIkSYGBgUpJSdGCBQus4WrVqlU6deqU9uzZIycnJ0ksHw8AAACg4tl9WaDFYtGkSZP0888/68yZMzpz5ox+/vlnTZgwQRaLpczj5OfnKzU1VRERETbtERER2rNnT4nbJCcnF+vfq1cvpaSk6OLFi5Kk9957T6GhoRo3bpy8vLzUrl07zZkzRwUFBaXWkpeXp9zcXJsHAAAAANjD7nBVJDs7W2lpaTpw4IBOnDhh9/Y5OTkqKCiQl5eXTbuXl5eysrJK3CYrK6vE/pcuXVJOTo4k6aefftJbb72lgoICJSYmaurUqXr++ec1e/bsUmuJj4+Xh4eH9eHr62v38QAAAACo3uwOV7m5uRo2bJh8fHzUpUsX/fOf/5SPj4/uv/9+nTlzxu4CLp/tMgzjijNgJfX/c3thYaEaNWqk5cuXKzg4WIMHD9aUKVO0dOnSUseMi4uzzsKdOXNGGRkZdh8HAAAAgOrN7nA1ZswYffHFF9q8ebNOnz6tM2fO6IMPPlBKSorGjh1b5nE8PT3l4OBQbJYqOzu72OxUkcaNG5fY39HRUQ0aNJAkeXt7q1WrVnJwcLD2CQwMVFZWlvLz80sc18XFRXXq1LF5AAAAAIA97A5Xmzdv1qpVq9SrVy/VqVNH7u7u6tWrl1asWKHNmzeXeRxnZ2cFBwcrKSnJpj0pKUlhYWElbhMaGlqs/7Zt2xQSEmJdvKJz58764YcfVFhYaO3z3//+V97e3nJ2di5zfQAAAABgD7vDVYMGDeTh4VGs3cPDQ/Xq1bNrrNjYWL366qtatWqVDh06pEmTJik9PV3R0dGS/rhc74EHHrD2j46O1tGjRxUbG6tDhw5p1apVWrlypR5//HFrn4cfflgnT57UhAkT9N///lebN2/WnDlzNG7cOHsPFQAAAADKzO6l2KdOnarY2Fi9/vrr8vb2lvTHQhNPPPGEpk2bZtdYUVFROnnypGbNmqXMzEy1a9dOiYmJ1qXTMzMzlZ6ebu0fEBCgxMRETZo0SYsXL5aPj48WLVpkXYZdknx9fbVt2zZNmjRJ7du3V5MmTTRhwgT93//9n72HCgAAAABlZne4Wrp0qX744Qf5+flZb/Sbnp4uFxcXnThxQq+88oq17759+646XkxMjGJiYkp8bc2aNcXaunTpctVxQ0ND9fnnn1913wAAAABgFrvDVf/+/SugDAAAAACo2uwOV9OnT6+IOgAAAACgSrM7XBVJTU3VoUOHZLFYFBQUpI4dO5pZFwAAAABUKXaHq+zsbA0ePFg7d+5U3bp1ZRiGzpw5o27dumn9+vVq2LBhRdQJAAAAANc1u5dif/TRR5Wbm6uDBw/q1KlT+vXXX/XNN98oNzdX48ePr4gaAQAAAOC6Z/fM1datW/XRRx8pMDDQ2hYUFKTFixcrIiLC1OIAAAAAoKqwe+aqsLBQTk5OxdqdnJxUWFhoSlEAAAAAUNXYHa5uv/12TZgwQcePH7e2HTt2TJMmTVL37t1NLQ4AAAAAqgq7w9XLL7+ss2fPyt/fXy1atFDLli0VEBCgs2fP6qWXXqqIGgEAAADgumf3d658fX21b98+JSUl6bvvvpNhGAoKClKPHj0qoj4AAAAAqBLsCleXLl2Sq6ur0tLS1LNnT/Xs2bOi6gIAAACAKsWuywIdHR3l5+engoKCiqoHAAAAAKoku79zNXXqVMXFxenUqVMVUQ8AAAAAVEl2f+dq0aJF+uGHH+Tj4yM/Pz/Vrl3b5vV9+/aZVhwAAAAAVBV2h6t+/frJYrFURC0AAAAAUGXZHa5mzJhRAWUAAAAAQNVW5u9cnT9/XuPGjVOTJk3UqFEjDRkyRDk5ORVZGwAAAABUGWUOV9OnT9eaNWvUp08fDR48WElJSXr44YcrsjYAAAAAqDLKfFngpk2btHLlSg0ePFiSdP/996tz584qKCiQg4NDhRUIAAAAAFVBmWeuMjIyFB4ebn1+yy23yNHRUcePH6+QwgAAAACgKilzuCooKJCzs7NNm6Ojoy5dumR6UQAAAABQ1ZT5skDDMDRixAi5uLhY2y5cuKDo6Gibe11t2rTJ3AoBAAAAoAooc7gaPnx4sbb777/f1GIAAAAAoKoqc7havXp1RdYBAAAAAFVamb9zBQAAAAAoHeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwQaWHqyVLliggIECurq4KDg7Wp59+esX+u3btUnBwsFxdXdW8eXMtW7as1L7r16+XxWJR//79Ta4aAAAAAGxVarjasGGDJk6cqClTpmj//v0KDw9XZGSk0tPTS+x/+PBh9e7dW+Hh4dq/f7+eeuopjR8/Xhs3bizW9+jRo3r88ccVHh5e0YcBAAAAAJUbrhYuXKjRo0drzJgxCgwMVEJCgnx9fbV06dIS+y9btkzNmjVTQkKCAgMDNWbMGI0aNUoLFiyw6VdQUKChQ4dq5syZat68+V9xKAAAAACquUoLV/n5+UpNTVVERIRNe0REhPbs2VPiNsnJycX69+rVSykpKbp48aK1bdasWWrYsKFGjx5dplry8vKUm5tr8wAAAAAAe1RauMrJyVFBQYG8vLxs2r28vJSVlVXiNllZWSX2v3TpknJyciRJu3fv1sqVK7VixYoy1xIfHy8PDw/rw9fX186jAQAAAFDdVfqCFhaLxea5YRjF2q7Wv6j97Nmzuv/++7VixQp5enqWuYa4uDidOXPG+sjIyLDjCAAAAABAcqysHXt6esrBwaHYLFV2dnax2akijRs3LrG/o6OjGjRooIMHD+rIkSPq27ev9fXCwkJJkqOjo77//nu1aNGi2LguLi5ycXG51kMCAAAAUI1V2syVs7OzgoODlZSUZNOelJSksLCwErcJDQ0t1n/btm0KCQmRk5OT2rRpo6+//lppaWnWx1133aVu3bopLS2Ny/0AAAAAVJhKm7mSpNjYWA0bNkwhISEKDQ3V8uXLlZ6erujoaEl/XK537Ngxvf7665Kk6Ohovfzyy4qNjdXYsWOVnJyslStXat26dZIkV1dXtWvXzmYfdevWlaRi7QAAAABgpkoNV1FRUTp58qRmzZqlzMxMtWvXTomJifLz85MkZWZm2tzzKiAgQImJiZo0aZIWL14sHx8fLVq0SAMHDqysQwAAAAAASZUcriQpJiZGMTExJb62Zs2aYm1dunTRvn37yjx+SWMAAAAAgNkqfbVAAAAAAPg7IFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsfKLgAAAABA1eQ/eXOFjX1kbp8KG7uiMHMFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJqj0cLVkyRIFBATI1dVVwcHB+vTTT6/Yf9euXQoODparq6uaN2+uZcuW2by+YsUKhYeHq169eqpXr5569OihvXv3VuQhAAAAAEDlhqsNGzZo4sSJmjJlivbv36/w8HBFRkYqPT29xP6HDx9W7969FR4erv379+upp57S+PHjtXHjRmufnTt36r777tOOHTuUnJysZs2aKSIiQseOHfurDgsAAABANVSp4WrhwoUaPXq0xowZo8DAQCUkJMjX11dLly4tsf+yZcvUrFkzJSQkKDAwUGPGjNGoUaO0YMECa5833nhDMTEx6tChg9q0aaMVK1aosLBQ27dv/6sOCwAAAEA1VGnhKj8/X6mpqYqIiLBpj4iI0J49e0rcJjk5uVj/Xr16KSUlRRcvXixxm/Pnz+vixYuqX79+qbXk5eUpNzfX5gEAAAAA9qi0cJWTk6OCggJ5eXnZtHt5eSkrK6vEbbKyskrsf+nSJeXk5JS4zeTJk9WkSRP16NGj1Fri4+Pl4eFhffj6+tp5NAAAAACqu0pf0MJisdg8NwyjWNvV+pfULknz58/XunXrtGnTJrm6upY6ZlxcnM6cOWN9ZGRk2HMIAAAAACDHytqxp6enHBwcis1SZWdnF5udKtK4ceMS+zs6OqpBgwY27QsWLNCcOXP00UcfqX379lesxcXFRS4uLuU4CgAAAAD4Q6XNXDk7Oys4OFhJSUk27UlJSQoLCytxm9DQ0GL9t23bppCQEDk5OVnbnnvuOT3zzDPaunWrQkJCzC8eAAAAAC5TqZcFxsbG6tVXX9WqVat06NAhTZo0Senp6YqOjpb0x+V6DzzwgLV/dHS0jh49qtjYWB06dEirVq3SypUr9fjjj1v7zJ8/X1OnTtWqVavk7++vrKwsZWVl6dy5c3/58QEAAACoPirtskBJioqK0smTJzVr1ixlZmaqXbt2SkxMlJ+fnyQpMzPT5p5XAQEBSkxM1KRJk7R48WL5+Pho0aJFGjhwoLXPkiVLlJ+fr0GDBtnsa/r06ZoxY8ZfclwAAAAAqp9KDVeSFBMTo5iYmBJfW7NmTbG2Ll26aN++faWOd+TIEZMqAwAAAICyq/TVAgEAAADg74BwBQAAAAAmIFwBAAAAgAkIVwAAAABggkpf0AIAgL+S/+TNFTb2kbl9KmxsAMD1j5krAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAElR6ulixZooCAALm6uio4OFiffvrpFfvv2rVLwcHBcnV1VfPmzbVs2bJifTZu3KigoCC5uLgoKChIb7/9dkWVDwAAAACSKjlcbdiwQRMnTtSUKVO0f/9+hYeHKzIyUunp6SX2P3z4sHr37q3w8HDt379fTz31lMaPH6+NGzda+yQnJysqKkrDhg3TgQMHNGzYMN1777364osv/qrDAgAAAFANVWq4WrhwoUaPHq0xY8YoMDBQCQkJ8vX11dKlS0vsv2zZMjVr1kwJCQkKDAzUmDFjNGrUKC1YsMDaJyEhQT179lRcXJzatGmjuLg4de/eXQkJCX/RUQEAAACojhwra8f5+flKTU3V5MmTbdojIiK0Z8+eErdJTk5WRESETVuvXr20cuVKXbx4UU5OTkpOTtakSZOK9blSuMrLy1NeXp71+ZkzZyRJubm59hxShSrMO18h45Z2jBW1v9L2+VfvryL3eb28p5WBY7w218u/jb873tO/B36PwPWhOvxbLKrDMIyr9q20cJWTk6OCggJ5eXnZtHt5eSkrK6vEbbKyskrsf+nSJeXk5Mjb27vUPqWNKUnx8fGaOXNmsXZfX9+yHk6V5ZHw99/n331/lbXPvxrHWPX3Vx3wnv498HsErg/X27/Fs2fPysPD44p9Ki1cFbFYLDbPDcMo1na1/pe32ztmXFycYmNjrc8LCwt16tQpNWjQ4Irb4Y8k7+vrq4yMDNWpU6eyy0EVwXmD8uC8QXlw3qA8OG/wZ4Zh6OzZs/Lx8blq30oLV56ennJwcCg2o5SdnV1s5qlI48aNS+zv6OioBg0aXLFPaWNKkouLi1xcXGza6tatW9ZDgaQ6derw4QO7cd6gPDhvUB6cNygPzhsUudqMVZFKW9DC2dlZwcHBSkpKsmlPSkpSWFhYiduEhoYW679t2zaFhITIycnpin1KGxMAAAAAzFCplwXGxsZq2LBhCgkJUWhoqJYvX6709HRFR0dL+uNyvWPHjun111+XJEVHR+vll19WbGysxo4dq+TkZK1cuVLr1q2zjjlhwgT985//1Lx589SvXz+9++67+uijj/TZZ59VyjECAAAAqB4qNVxFRUXp5MmTmjVrljIzM9WuXTslJibKz89PkpSZmWlzz6uAgAAlJiZq0qRJWrx4sXx8fLRo0SINHDjQ2icsLEzr16/X1KlTNW3aNLVo0UIbNmxQp06d/vLjqw5cXFw0ffr0YpdVAlfCeYPy4LxBeXDeoDw4b1BeFqMsawoCAAAAAK6oUm8iDAAAAAB/F4QrAAAAADAB4QoAAAAATEC4AgAAAAATEK5wVfHx8frHP/4hd3d3NWrUSP3799f3339v02fEiBGyWCw2j1tvvbWSKsb1YunSpWrfvr31JoyhoaHasmWL9XXDMDRjxgz5+PioZs2a6tq1qw4ePFiJFeN6cLXzhs8bXE18fLwsFosmTpxobePzBldT0nnD5w3sRbjCVe3atUvjxo3T559/rqSkJF26dEkRERH67bffbPrdcccdyszMtD4SExMrqWJcL5o2baq5c+cqJSVFKSkpuv3229WvXz/rHzTz58/XwoUL9fLLL+vLL79U48aN1bNnT509e7aSK0dlutp5I/F5g9J9+eWXWr58udq3b2/TzucNrqS080bi8wZ2MgA7ZWdnG5KMXbt2WduGDx9u9OvXr/KKQpVRr14949VXXzUKCwuNxo0bG3PnzrW+duHCBcPDw8NYtmxZJVaI61HReWMYfN6gdGfPnjVuuOEGIykpyejSpYsxYcIEwzAMPm9wRaWdN4bB5w3sx8wV7HbmzBlJUv369W3ad+7cqUaNGqlVq1YaO3assrOzK6M8XKcKCgq0fv16/fbbbwoNDdXhw4eVlZWliIgIax8XFxd16dJFe/bsqcRKcT25/LwpwucNSjJu3Dj16dNHPXr0sGnn8wZXUtp5U4TPG9jDsbILQNViGIZiY2N12223qV27dtb2yMhI3XPPPfLz89Phw4c1bdo03X777UpNTeXu5tXc119/rdDQUF24cEFubm56++23FRQUZP2DxsvLy6a/l5eXjh49Whml4jpS2nkj8XmDkq1fv1779u3Tl19+Wey1rKwsSXzeoLgrnTcSnzewH+EKdnnkkUf01Vdf6bPPPrNpj4qKsv7crl07hYSEyM/PT5s3b9bdd9/9V5eJ60jr1q2Vlpam06dPa+PGjRo+fLh27dplfd1isdj0NwyjWBuqn9LOm6CgID5vUExGRoYmTJigbdu2ydXVtdR+fN7gz8py3vB5A3txWSDK7NFHH9V7772nHTt2qGnTplfs6+3tLT8/P/3vf//7i6rD9crZ2VktW7ZUSEiI4uPjddNNN+nFF19U48aNJf3//6NcJDs7u9j/XUb1U9p5UxI+b5Camqrs7GwFBwfL0dFRjo6O2rVrlxYtWiRHR0frZwqfN/izq503BQUFxbbh8wZXQ7jCVRmGoUceeUSbNm3Sxx9/rICAgKtuc/LkSWVkZMjb2/svqBBViWEYysvLU0BAgBo3bqykpCTra/n5+dq1a5fCwsIqsUJcj4rOm5LweYPu3bvr66+/VlpamvUREhKioUOHKi0tTc2bN+fzBsVc7bxxcHAotg2fN7gaLgvEVY0bN05r167Vu+++K3d3d+v/+fPw8FDNmjV17tw5zZgxQwMHDpS3t7eOHDmip556Sp6enhowYEAlV4/K9NRTTykyMlK+vr46e/as1q9fr507d2rr1q3We4nMmTNHN9xwg2644QbNmTNHtWrV0pAhQyq7dFSiK503fN6gJO7u7jbfA5ak2rVrq0GDBtZ2Pm9wuaudN3zeoDwIV7iqpUuXSpK6du1q07569WqNGDFCDg4O+vrrr/X666/r9OnT8vb2Vrdu3bRhwwa5u7tXQsW4Xvzyyy8aNmyYMjMz5eHhofbt22vr1q3q2bOnJOnJJ5/U77//rpiYGP3666/q1KmTtm3bxnlTzV3pvPn999/5vEG58HkDe/H3DcrDYhiGUdlFAAAAAEBVx3euAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAKhmLBaL3nnnncouAwD+dghXAAC7ZWdn66GHHlKzZs3k4uKixo0bq1evXkpOTq7s0q4b10OAmTFjhjp06FCpNQBAdeJY2QUAAKqegQMH6uLFi3rttdfUvHlz/fLLL9q+fbtOnTpV2aUBAFBpmLkCANjl9OnT+uyzzzRv3jx169ZNfn5+uuWWWxQXF6c+ffpY+505c0YPPvigGjVqpDp16uj222/XgQMHbMaaO3euvLy85O7urtGjR2vy5Mk2My1du3bVxIkTbbbp37+/RowYYX2en5+vJ598Uk2aNFHt2rXVqVMn7dy50/r6mjVrVLduXX344YcKDAyUm5ub7rjjDmVmZtqMu2rVKrVt21YuLi7y9vbWI488Ytex2Gv16tUKDAyUq6ur2rRpoyVLllhfO3LkiCwWizZt2qRu3bqpVq1auummm4rNDK5YsUK+vr6qVauWBgwYoIULF6pu3brW4545c6YOHDggi8Uii8WiNWvWWLfNycnRgAEDVKtWLd1www167733rul4AACEKwCAndzc3OTm5qZ33nlHeXl5JfYxDEN9+vRRVlaWEhMTlZqaqptvvlndu3e3zm69+eabmj59umbPnq2UlBR5e3vbBIyyGjlypHbv3q3169frq6++0j333KM77rhD//vf/6x9zp8/rwULFuhf//qXPvnkE6Wnp+vxxx+3vr506VKNGzdODz74oL7++mu99957atmyZZmPxV4rVqzQlClTNHv2bB06dEhz5szRtGnT9Nprr9n0mzJlih5//HGlpaWpVatWuu+++3Tp0iVJ0u7duxUdHa0JEyYoLS1NPXv21OzZs63bRkVF6bHHHlPbtm2VmZmpzMxMRUVFWV+fOXOm7r33Xn311Vfq3bu3hg4dyswjAFwrAwAAO7311ltGvXr1DFdXVyMsLMyIi4szDhw4YH19+/btRp06dYwLFy7YbNeiRQvjlVdeMQzDMEJDQ43o6Gib1zt16mTcdNNN1uddunQxJkyYYNOnX79+xvDhww3DMIwffvjBsFgsxrFjx2z6dO/e3YiLizMMwzBWr15tSDJ++OEH6+uLFy82vLy8rM99fHyMKVOmlHisZTmWkkgy3n777RJf8/X1NdauXWvT9swzzxihoaGGYRjG4cOHDUnGq6++an394MGDhiTj0KFDhmEYRlRUlNGnTx+bMYYOHWp4eHhYn0+fPt3m/fxzbVOnTrU+P3funGGxWIwtW7aUejwAgKtj5goAYLeBAwfq+PHjeu+999SrVy/t3LlTN998s/Wys9TUVJ07d04NGjSwznS5ubnp8OHD+vHHHyVJhw4dUmhoqM24lz+/mn379skwDLVq1cpmP7t27bLuR5Jq1aqlFi1aWJ97e3srOztb0h+Lcxw/flzdu3cvcR9lORZ7nDhxQhkZGRo9erTNeM8++2yx8dq3b29Tc1G9kvT999/rlltusel/+fMr+fPYtWvXlru7u3VsAED5sKAFAKBcXF1d1bNnT/Xs2VNPP/20xowZo+nTp2vEiBEqLCyUt7e3zXefihR9J6gsatSoIcMwbNouXrxo/bmwsFAODg5KTU2Vg4ODTT83Nzfrz05OTjavWSwW67g1a9a8Yg1mHcufx5P+uDSwU6dONq9dfgx/rttisdhsbxiGta3I5e/VlZT0nhSNDQAoH8IVAMAUQUFB1qXHb775ZmVlZcnR0VH+/v4l9g8MDNTnn3+uBx54wNr2+eef2/Rp2LChzcITBQUF+uabb9StWzdJUseOHVVQUKDs7GyFh4eXq253d3f5+/tr+/bt1nH/rCzHYg8vLy81adJEP/30k4YOHVrucdq0aaO9e/fatKWkpNg8d3Z2VkFBQbn3AQCwD+EKAGCXkydP6p577tGoUaPUvn17ubu7KyUlRfPnz1e/fv0kST169FBoaKj69++vefPmqXXr1jp+/LgSExPVv39/hYSEaMKECRo+fLhCQkJ022236Y033tDBgwfVvHlz675uv/12xcbGavPmzWrRooVeeOEFnT592vp6q1atNHToUD3wwAN6/vnn1bFjR+Xk5Ojjjz/WjTfeqN69e5fpmGbMmKHo6Gg1atRIkZGROnv2rHbv3q1HH320TMdSmsOHDystLc2mrWXLlpoxY4bGjx+vOnXqKDIyUnl5eUpJSdGvv/6q2NjYMtX86KOP6p///KcWLlyovn376uOPP9aWLVtsZrP8/f2tNTRt2lTu7u5ycXEp0/gAgHKo1G98AQCqnAsXLhiTJ082br75ZsPDw8OoVauW0bp1a2Pq1KnG+fPnrf1yc3ONRx991PDx8TGcnJwMX19fY+jQoUZ6erq1z+zZsw1PT0/Dzc3NGD58uPHkk0/aLMCQn59vPPzww0b9+vWNRo0aGfHx8TYLWhT1efrppw1/f3/DycnJaNy4sTFgwADjq6++MgzjjwUt/rzIg2EYxttvv21c/p/AZcuWGa1btzacnJwMb29v49FHH7XrWC4nqcTHjh07DMMwjDfeeMPo0KGD4ezsbNSrV8/45z//aWzatMkwjP+/oMX+/fut4/3666822xuGYSxfvtxo0qSJUbNmTaN///7Gs88+azRu3NjmdzVw4ECjbt26hiRj9erV1touX2zDw8PD+joAoHwshmHHBdoAAFSgGTNm6J133ik224OyGTt2rL777jt9+umnlV0KAFRLXBYIAEAVtWDBAvXs2VO1a9fWli1b9Nprr5XrXmEAAHMQrgAAqKL27t2r+fPn6+zZs2revLkWLVqkMWPGVHZZAFBtcVkgAAAAAJiAmwgDAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACb4f6vZxcDWsII0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_length_distribution(data, title, sequence_type='output'):\n",
    "    if sequence_type == 'input':\n",
    "        lengths = [len(in_seq) for in_seq, _ in data]\n",
    "    elif sequence_type == 'output':\n",
    "        lengths = [len(out_seq) for _, out_seq in data]\n",
    "    else:\n",
    "        raise ValueError(\"sequence_type must be either 'input' or 'output'\")\n",
    "\n",
    "    length_counts = Counter(lengths)\n",
    "    total_examples = len(data)\n",
    "    length_proportions = {length: count / total_examples for length, count in sorted(length_counts.items())}\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(length_proportions.keys(), length_proportions.values())\n",
    "    plt.xlabel(\"Sequence Length\")\n",
    "    plt.ylabel(\"Proportion of Examples\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_length_distribution(new_train_data, \"Training Set Output Length Distribution\", sequence_type='output')\n",
    "\n",
    "plot_length_distribution(new_test_data, \"Test Set Output Length Distribution\", sequence_type='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cSgpuXNBWOg"
   },
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kcIZe61Nd9P"
   },
   "source": [
    "Using the existing code, can you\n",
    "- create loaders for the new training and test set reusing `SCANDataset`\n",
    "- train a new GRU model on the new train set reusing `train_model`\n",
    "- generate predicted sequences for the new GRU model reusing `evaluate_model`\n",
    "- code a new function to measure to how the model performs on target sequences grouped by length in terms of exact match and BLEU.\n",
    "\n",
    "Then answer the following questions:\n",
    "- What effect do you expect shifts in distribution to have on model performance? Compare evaluation metrics of your experiments on o.o.d and i.i.d. generalisation.\n",
    "- Is it realistic to expect these shifts in distribution in realistic settings where models are trained on natural language data?\n",
    "- Is it realistic to expect compositional generalisation to be sufficient to model pairs of inputs and outputs in natural language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "new_train_dataset = SCANDataset(new_train_data, input_w2i, output_w2i)\n",
    "new_train_loader = DataLoader(new_train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "new_test_dataset = SCANDataset(new_test_data, input_w2i, output_w2i)\n",
    "new_test_loader = DataLoader(new_test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/ANLP/ANLP_labs/lab_3/wandb/run-20251020_181903-ws5pg1gu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/ws5pg1gu' target=\"_blank\">5-0.001--00D</a></strong> to <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/ws5pg1gu' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/ws5pg1gu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [01:24<00:00,  6.20it/s]\n",
      "100%|██████████| 523/523 [01:22<00:00,  6.35it/s]\n",
      "100%|██████████| 523/523 [01:23<00:00,  6.29it/s]\n",
      "100%|██████████| 523/523 [01:25<00:00,  6.10it/s]\n",
      "100%|██████████| 523/523 [01:24<00:00,  6.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.19378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">5-0.001--00D</strong> at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/ws5pg1gu' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq/runs/ws5pg1gu</a><br> View project at: <a href='https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq' target=\"_blank\">https://wandb.ai/s2807348-the-university-of-edinburgh/scan-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251020_181903-ws5pg1gu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3920/3920 [01:02<00:00, 62.34it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "lr = 0.001\n",
    "new_gru_encoder, new_gru_decoder = train_model(f\"{n_epochs}-{lr}--00D\", n_epochs, lr)\n",
    "new_sequences = evaluate_model(new_gru_encoder,new_gru_decoder,new_test_dataset,max_len=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match accuracy: 0.853\n",
      "Length 24 | Accuracy: 0.869\n",
      "Length 25 | Accuracy: 0.877\n",
      "Length 26 | Accuracy: 0.889\n",
      "Length 27 | Accuracy: 0.944\n",
      "Length 28 | Accuracy: 0.786\n",
      "Length 30 | Accuracy: 0.910\n",
      "Length 32 | Accuracy: 0.848\n",
      "Length 33 | Accuracy: 0.922\n",
      "Length 36 | Accuracy: 0.422\n",
      "Length 40 | Accuracy: 0.703\n",
      "Length 48 | Accuracy: 0.633\n"
     ]
    }
   ],
   "source": [
    "def exact_match_per_length(sequences):\n",
    "    length2em = defaultdict(list)\n",
    "\n",
    "    for predicted_tokens, reference_tokens in sequences:\n",
    "        exact_match = int(predicted_tokens == reference_tokens)\n",
    "        ref_len = len(reference_tokens)\n",
    "        length2em[ref_len] += [exact_match]#按照不同length进行统计 length：[count1][count2][count3]\n",
    "\n",
    "    # Compute accuracy per output length\n",
    "    for length in sorted(length2em.keys()):\n",
    "        acc = sum(length2em[length]) / len(length2em[length])\n",
    "        print(f\"Length {length:2d} | Accuracy: {acc:.3f}\")\n",
    "\n",
    "exact_match(new_sequences)\n",
    "exact_match_per_length(new_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
