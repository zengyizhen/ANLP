# Speech and Language Processing
James H. Martin
## Chapter 1: Large Language Models

Week 1: JM3 *2.0-2.1(\*)*, 2.6 (\*), 2.7, 17.1, 2.2 (\*), 2.3, 2.4 (\*)

### 2.0 Word and Tokens
**Tokenization**: the task of separating out or
tokenizing words and word parts from running text

**How to represent words**
- Unicode
- UTF-8
- morpheme
  
**The standard way to tokenize text**
- **Byte-Pair Encoding (BPE)**: This algorithm uses simple statistics of letter sequences to induce a vocabulary of subword tokens.
- All tokenization systems also depend on **regular expressions** as a processing step.

**Edit distance**: measures how similar
two words or strings are based on the number of edits (insertions, deletions, substitutions) it takes to change one string into the other. 

### 2.1 Word (How to define "word")


>I do uh main- mainly business data processing

 This **Utterance**  has two kinds of disfluencies.
- Fragment: main-.
- Fillers/filled pauses: um/uh.
  
    Fillers can be kept cause they may signal clause or idea(or a cue to speaker identification), so for speech recognition they are treated as regular words.

---
  
>They picnicked by the pool, then lay back on the grass and looked at the stars.

    👉This sentence has 16 words if we don’t count punctuation as words, 18 if we count punctuation. If we ignore punctuation, the picnic sentence has 14 types and 16 instances.

Large language models generally count **punctuation** as separate words. **Word types** are the number of distinct words in a corpus; if the set of words in the vocabulary
word instance is $V$, the **number of types** is the vocabulary size $|V|$.
**Word instances** are the total
number N of running words.



Notice **Capitalized problem**: Should *They* and *they* be the same word type?

---

#### **Orthographic problem** 
Chinese, Japanese and Thai don't have orthographic at all
##### 📊 Example: Chinese
**Features**: each character generally represents a single
unit of meaning (called a **morpheme**, introduced below) and is pronounceable as a
single syllable.  Deciding what counts as a word in Chinese is complex. 

- Chinese Treebank(3 words):  
>姚明YaoMing
进入
reaches
总决赛
finals
- 'Peking University' standard(5 words):  
>姚
Yao
明
Ming
进入
reaches
总
overall
决赛
finals
- Using characters
as the basic elements(7 words) works pretty well👍 since characters are at a reasonable **semantic level** for most
applications
> 姚
Yao
明
Ming
进
enter
入
enter
总
overall
决
decision
赛
game
---
#### **The number of words problem**
The number of words grows without bound
- function words: a, of, the
- content words: nouns, adjectives and verbs
---
#### **Result**
NLP models use smaller units called **subwords** that can be recombined to model new words that our model has never
seen before.   
**Next step**: Defining subwords (morphemes and characters)