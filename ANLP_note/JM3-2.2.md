# Speech and Language Processing
James H. Martin
## Chapter 1: Large Language Models

Week 1: JM3 *2.0-2.1(\*)*, 2.6 (\*), 2.7, 17.1, *2.2 (\*)*, 2.3, 2.4 (\*)

### 2.2 Morphemes: Parts of Words

**MorphemesËØçÁ¥†**: words have **components** that themselves have coherent meanings.
>The word fox consists of one morpheme (the morpheme fox)
>
> The word cats consistsof two: the morpheme cat and the morpheme -s that indicates plural
>
> Doc work-ed care-ful-ly wash-ing the glass-es

Classes of **morphemes**: 
- **Stems** convey core meaning: small, cat, walk
- **Affixes** can modify meaning: +ed, +er, un+; suffix,prefix, infix, circumfix
    - **inflectional morphemes**: play a **syntactic** role or expresses **grammatical features**, such as marking **agreement**, and their meanings tend to be predictable.

      *eg. -s/-es for marking plural; -ed for marking the past tense*
       - üëéAgreement: long-distance dependencies
    - **Derivational morphemes**
        - may change the part of speech or meaning of a word
        - is not driven by syntactic relations or agreement outside the word
        - may be ‚Äúpicky‚Äù: intractibil+ity but not intractible+ness
        - applies closer to the stem; whereas inflection occurs at word edges: govern+ment+s, centr+al+ize+d

- [ ] ‚ùó**Stems vs. lemmas**?
- **Clitics**: acts syntactically like a word but is reduced in form and attached
  
  *eg. ‚Äôve in the word I‚Äôve*
- **Compounds**: combine multiple stems to create a new word, as in home+work, note+book
- **Reduplication** & **Root** & **Pattern**(non-concatenative)
---
#### Morphemes can be ambiguous (in several ways)
- Stems can be ambiguous:
bank (financial institution) vs. bank (land alongside a river)
- Affixes can also be ambiguous:
+s: plural of noun (dogs), or present tense of 3rd person singular verb (swims)?
- Consider she+‚Äôs . Does it mean she is or she has?
- Morpheme **combinations** can be ambiguous.
  
        (un+tie)+able: Able to be untied

        un+(tie+able): Unable to be tied

---

(Optional)Two dimensions relevant for computational word tokenization while morphologies of language can differ along many dimensions.
- The number of morphemes per word.
    -  **isolating/analytic languages**: each word on average has just over one morpheme. *eg. Vietnamese and CantoneseÂπø‰∏úËØù*
    -  **synthetic languages**: a single word may
have very many morphemes
    -  **polysynthetic**
-  The degree to which morphemes are easily segmentable
    - **agglutinative languages**: morphemes have relatively clean boundaries. *eg.Turkish*
    - **fusion languages**:  a single affix may conflate multiple morphemes *eg.Russian*
---
#### Morpheme-based tokenization

‚úÖ reduce the sparse data problem

‚úÖ more meaningful than individual characters, and token sequences will be shorter

‚ùå We will still encounter unseen tokens (e.g., rare or newly coined stems

‚ùå need a morphological segmentation system (morpheme tokenizer) for every language

---
#### Subword tokenization

- Basic idea: split words into frequently-occurring **sub-units** (which may or may 
not coincide with morphemes).

- Popular algorithms: **Byte Pair Encoding (BPE)** and **UnigramLM**.

- Such algorithms all have two modes:

    - **Token learner**: given a (pre-processed) training corpus, return a vocabulary of tokens (in UnigramLM, also frequencies)

    - **Token segmenter**: given a new sentence, segment it into tokens of the vocabulary according to a function (varies among tokenizers).

---
**Conclusion**: it's very difficult to use morphemes as a standard for tokenization **cross-lingually/multilingual**.
